{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba1d63558925460088b0c3bcf223fb68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ed14136b4ea48a38b5f8585f1b0f7c4",
              "IPY_MODEL_3ce090caf5cb4bdcba2ada9589084051",
              "IPY_MODEL_bf0f3ec8890e4222baab3f97ea444865"
            ],
            "layout": "IPY_MODEL_fecb56a725aa47e79faaa404b3cdedee"
          }
        },
        "4ed14136b4ea48a38b5f8585f1b0f7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_746c2522b3de4e5f89d2b9621f4ee6df",
            "placeholder": "​",
            "style": "IPY_MODEL_563ab3890cd04975bb6cfb6a93f4b7f1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3ce090caf5cb4bdcba2ada9589084051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_609d62de900448caa55e5c1ca5bd10bf",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_838b238d37504f5d896dd86149bfed91",
            "value": 614
          }
        },
        "bf0f3ec8890e4222baab3f97ea444865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3cd29020e874ad7a1489d822711ea38",
            "placeholder": "​",
            "style": "IPY_MODEL_59d73e7237d441afb391ebaac9d8518e",
            "value": " 614/614 [00:00&lt;00:00, 8.92kB/s]"
          }
        },
        "fecb56a725aa47e79faaa404b3cdedee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "746c2522b3de4e5f89d2b9621f4ee6df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563ab3890cd04975bb6cfb6a93f4b7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "609d62de900448caa55e5c1ca5bd10bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838b238d37504f5d896dd86149bfed91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3cd29020e874ad7a1489d822711ea38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59d73e7237d441afb391ebaac9d8518e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4579e51f7a7f4fc799c105c3a47a33a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fb56020769f4aa5bad1936537726415",
              "IPY_MODEL_d6ade2ced763446f807e57567e5362f3",
              "IPY_MODEL_0b86286d1ef54b2ab4134bced4020fac"
            ],
            "layout": "IPY_MODEL_35e33eea90ba4295b92ca2f293f19de3"
          }
        },
        "2fb56020769f4aa5bad1936537726415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3afb10b5076b4aefa34d9a735b367baa",
            "placeholder": "​",
            "style": "IPY_MODEL_1d338a9176444855941a150aad9463b4",
            "value": "vocab.json: 100%"
          }
        },
        "d6ade2ced763446f807e57567e5362f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9437716eefe2466fa56b276f4185bc4e",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9346e474a85746c2a3112bb103f25675",
            "value": 1042301
          }
        },
        "0b86286d1ef54b2ab4134bced4020fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e8e78661e7f4f17b00e12358a055acd",
            "placeholder": "​",
            "style": "IPY_MODEL_1c3ef35703fc451bbba9288da1a3dccc",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 6.21MB/s]"
          }
        },
        "35e33eea90ba4295b92ca2f293f19de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afb10b5076b4aefa34d9a735b367baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d338a9176444855941a150aad9463b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9437716eefe2466fa56b276f4185bc4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9346e474a85746c2a3112bb103f25675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e8e78661e7f4f17b00e12358a055acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c3ef35703fc451bbba9288da1a3dccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34f81e7812384d0b8c70945a76402f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ccf407824604b81a3f5f6fc5602cef6",
              "IPY_MODEL_74123e3c0fad4e60a3a43c68fdb7cb58",
              "IPY_MODEL_ab182cb59cb0406e924e6630d8e5062c"
            ],
            "layout": "IPY_MODEL_5e0b087b58244ac8b8172a374e17f42c"
          }
        },
        "9ccf407824604b81a3f5f6fc5602cef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c6f215a3ef3479a82a3858d276baa5a",
            "placeholder": "​",
            "style": "IPY_MODEL_bb9e600ee22743848aabaf7b4a02a61a",
            "value": "merges.txt: 100%"
          }
        },
        "74123e3c0fad4e60a3a43c68fdb7cb58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1752d54a739847fa953e48ee6f9e141d",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d858f6bfda034675975c61f0ba0587f7",
            "value": 456318
          }
        },
        "ab182cb59cb0406e924e6630d8e5062c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24e10af4542c4e6f98f89831eb72d25a",
            "placeholder": "​",
            "style": "IPY_MODEL_1abb97fc5ba24c239427ae61223fe83e",
            "value": " 456k/456k [00:00&lt;00:00, 7.36MB/s]"
          }
        },
        "5e0b087b58244ac8b8172a374e17f42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c6f215a3ef3479a82a3858d276baa5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9e600ee22743848aabaf7b4a02a61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1752d54a739847fa953e48ee6f9e141d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d858f6bfda034675975c61f0ba0587f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24e10af4542c4e6f98f89831eb72d25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1abb97fc5ba24c239427ae61223fe83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63e8c0c3b71741d3bad88d157c16cd2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8825903adbcd4870a94dbfc33f6b8042",
              "IPY_MODEL_b5d51af3b2704f669bb51c87f366eb76",
              "IPY_MODEL_db2881ce7a0944689e27587874acd229"
            ],
            "layout": "IPY_MODEL_d19ec843272a43ba8fb5666cb47d73ab"
          }
        },
        "8825903adbcd4870a94dbfc33f6b8042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e989e920111455e8e4de9ccf27e98ad",
            "placeholder": "​",
            "style": "IPY_MODEL_06b2d4c8fd1144929bd4101e387a65b3",
            "value": "config.json: 100%"
          }
        },
        "b5d51af3b2704f669bb51c87f366eb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_145bc787081b4de3b80c9533c71329f1",
            "max": 642,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5cd6ea58dcd48f18d39c6e8b3b43f2e",
            "value": 642
          }
        },
        "db2881ce7a0944689e27587874acd229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ae55ce4a853424daa4f5d4dad5193f9",
            "placeholder": "​",
            "style": "IPY_MODEL_ae47c2439b364ef08a95209e672a58c8",
            "value": " 642/642 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "d19ec843272a43ba8fb5666cb47d73ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e989e920111455e8e4de9ccf27e98ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b2d4c8fd1144929bd4101e387a65b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "145bc787081b4de3b80c9533c71329f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5cd6ea58dcd48f18d39c6e8b3b43f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ae55ce4a853424daa4f5d4dad5193f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae47c2439b364ef08a95209e672a58c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab851bf2717e405c9d6c5f4ae59bb45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44fec3194ef845c9b6e219899e8eba18",
              "IPY_MODEL_f5d9340287c443d293746e00f5db7c18",
              "IPY_MODEL_6fd248a70c6a46f6b31311c4e1ffdcb9"
            ],
            "layout": "IPY_MODEL_b0311d173fec4231bf08c9d3b7408979"
          }
        },
        "44fec3194ef845c9b6e219899e8eba18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba43d43b37a64f7f92c9a5ec3e20694c",
            "placeholder": "​",
            "style": "IPY_MODEL_d81616b411fd4e1fbb2f087bcefaacd9",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "f5d9340287c443d293746e00f5db7c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd8d3f94114c47d2b7b91147f8c6a710",
            "max": 862955157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79452e7ba6454911bb31a90f7cc3845f",
            "value": 862955157
          }
        },
        "6fd248a70c6a46f6b31311c4e1ffdcb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72a53836e53d451489ee12a8b0d860fd",
            "placeholder": "​",
            "style": "IPY_MODEL_58a6d1fdb8554598938e288ff34d54ef",
            "value": " 863M/863M [00:08&lt;00:00, 105MB/s]"
          }
        },
        "b0311d173fec4231bf08c9d3b7408979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba43d43b37a64f7f92c9a5ec3e20694c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d81616b411fd4e1fbb2f087bcefaacd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd8d3f94114c47d2b7b91147f8c6a710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79452e7ba6454911bb31a90f7cc3845f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72a53836e53d451489ee12a8b0d860fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a6d1fdb8554598938e288ff34d54ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c48e46d639749c0b55c99d32116035d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5bcb12210a749b9842587aeb676dc4d",
              "IPY_MODEL_d2a2ffcddfbf405ba148febd386714ba",
              "IPY_MODEL_60955ef6299c4e9bbd65920feb05e54e"
            ],
            "layout": "IPY_MODEL_6319e3a492124bb980369ddeb889445e"
          }
        },
        "c5bcb12210a749b9842587aeb676dc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf7744f812b42bbb6dc8e10dceab68b",
            "placeholder": "​",
            "style": "IPY_MODEL_01172f34e80e4c8bbb69fd910c0eeeea",
            "value": "generation_config.json: 100%"
          }
        },
        "d2a2ffcddfbf405ba148febd386714ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f236bdf0b09844be9d17f56def1ae3e4",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8eccc15343b14754b18cf053354b93a2",
            "value": 124
          }
        },
        "60955ef6299c4e9bbd65920feb05e54e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53a2e3c44b70432e98e06dbc0aaa5c12",
            "placeholder": "​",
            "style": "IPY_MODEL_bc8b0c0d1b3b4321acf9a8847d4db8db",
            "value": " 124/124 [00:00&lt;00:00, 1.75kB/s]"
          }
        },
        "6319e3a492124bb980369ddeb889445e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf7744f812b42bbb6dc8e10dceab68b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01172f34e80e4c8bbb69fd910c0eeeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f236bdf0b09844be9d17f56def1ae3e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eccc15343b14754b18cf053354b93a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53a2e3c44b70432e98e06dbc0aaa5c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8b0c0d1b3b4321acf9a8847d4db8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKbXbOIRgRv_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Depencies"
      ],
      "metadata": {
        "id": "KaVDOuu6gt0Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8cd2jPX_eL57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34209f20-37f0-4598-e65b-2c6545529679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apobmSo4qWnz",
        "outputId": "eec829b7-9c32-43f9-ea8c-975dfb32d166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y75goCzFet8J",
        "outputId": "7597ea5b-2783-48a0-e09d-1f4b2ebb3922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.2\n",
            "Collecting peft\n",
            "  Downloading peft-0.9.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.27.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: peft\n",
            "Successfully installed peft-0.9.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.1 responses-0.18.0\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install sentencepiece\n",
        "# ! pip install datasets\n",
        "! pip install transformers[torch]\n",
        "! pip install peft\n",
        "! pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGPc8KIeN8Rh",
        "outputId": "e8726394-4039-4fc6-8b57-5fa490e1ac08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB2XXYsVAUth",
        "outputId": "32dd50cf-9617-46d0-d398-cd528b012d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        " !pip install transformers pandas datasets accelerate sentencepiece tokenizers peft\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question answering Model"
      ],
      "metadata": {
        "id": "JdC7AesChJhM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PuFayN2bhIrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377,
          "referenced_widgets": [
            "ba1d63558925460088b0c3bcf223fb68",
            "4ed14136b4ea48a38b5f8585f1b0f7c4",
            "3ce090caf5cb4bdcba2ada9589084051",
            "bf0f3ec8890e4222baab3f97ea444865",
            "fecb56a725aa47e79faaa404b3cdedee",
            "746c2522b3de4e5f89d2b9621f4ee6df",
            "563ab3890cd04975bb6cfb6a93f4b7f1",
            "609d62de900448caa55e5c1ca5bd10bf",
            "838b238d37504f5d896dd86149bfed91",
            "c3cd29020e874ad7a1489d822711ea38",
            "59d73e7237d441afb391ebaac9d8518e",
            "4579e51f7a7f4fc799c105c3a47a33a6",
            "2fb56020769f4aa5bad1936537726415",
            "d6ade2ced763446f807e57567e5362f3",
            "0b86286d1ef54b2ab4134bced4020fac",
            "35e33eea90ba4295b92ca2f293f19de3",
            "3afb10b5076b4aefa34d9a735b367baa",
            "1d338a9176444855941a150aad9463b4",
            "9437716eefe2466fa56b276f4185bc4e",
            "9346e474a85746c2a3112bb103f25675",
            "0e8e78661e7f4f17b00e12358a055acd",
            "1c3ef35703fc451bbba9288da1a3dccc",
            "34f81e7812384d0b8c70945a76402f39",
            "9ccf407824604b81a3f5f6fc5602cef6",
            "74123e3c0fad4e60a3a43c68fdb7cb58",
            "ab182cb59cb0406e924e6630d8e5062c",
            "5e0b087b58244ac8b8172a374e17f42c",
            "2c6f215a3ef3479a82a3858d276baa5a",
            "bb9e600ee22743848aabaf7b4a02a61a",
            "1752d54a739847fa953e48ee6f9e141d",
            "d858f6bfda034675975c61f0ba0587f7",
            "24e10af4542c4e6f98f89831eb72d25a",
            "1abb97fc5ba24c239427ae61223fe83e",
            "63e8c0c3b71741d3bad88d157c16cd2f",
            "8825903adbcd4870a94dbfc33f6b8042",
            "b5d51af3b2704f669bb51c87f366eb76",
            "db2881ce7a0944689e27587874acd229",
            "d19ec843272a43ba8fb5666cb47d73ab",
            "3e989e920111455e8e4de9ccf27e98ad",
            "06b2d4c8fd1144929bd4101e387a65b3",
            "145bc787081b4de3b80c9533c71329f1",
            "c5cd6ea58dcd48f18d39c6e8b3b43f2e",
            "5ae55ce4a853424daa4f5d4dad5193f9",
            "ae47c2439b364ef08a95209e672a58c8",
            "ab851bf2717e405c9d6c5f4ae59bb45f",
            "44fec3194ef845c9b6e219899e8eba18",
            "f5d9340287c443d293746e00f5db7c18",
            "6fd248a70c6a46f6b31311c4e1ffdcb9",
            "b0311d173fec4231bf08c9d3b7408979",
            "ba43d43b37a64f7f92c9a5ec3e20694c",
            "d81616b411fd4e1fbb2f087bcefaacd9",
            "cd8d3f94114c47d2b7b91147f8c6a710",
            "79452e7ba6454911bb31a90f7cc3845f",
            "72a53836e53d451489ee12a8b0d860fd",
            "58a6d1fdb8554598938e288ff34d54ef",
            "7c48e46d639749c0b55c99d32116035d",
            "c5bcb12210a749b9842587aeb676dc4d",
            "d2a2ffcddfbf405ba148febd386714ba",
            "60955ef6299c4e9bbd65920feb05e54e",
            "6319e3a492124bb980369ddeb889445e",
            "bbf7744f812b42bbb6dc8e10dceab68b",
            "01172f34e80e4c8bbb69fd910c0eeeea",
            "f236bdf0b09844be9d17f56def1ae3e4",
            "8eccc15343b14754b18cf053354b93a2",
            "53a2e3c44b70432e98e06dbc0aaa5c12",
            "bc8b0c0d1b3b4321acf9a8847d4db8db"
          ]
        },
        "id": "xt_Yn6YxDqCh",
        "outputId": "3aaf9b6f-e0ac-4a7e-e719-14d03e071f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba1d63558925460088b0c3bcf223fb68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4579e51f7a7f4fc799c105c3a47a33a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34f81e7812384d0b8c70945a76402f39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63e8c0c3b71741d3bad88d157c16cd2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab851bf2717e405c9d6c5f4ae59bb45f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c48e46d639749c0b55c99d32116035d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load model directly\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM ,pipeline\n",
        "\n",
        "\n",
        "model_name = \"microsoft/DialoGPT-medium\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "# ,torch_dtype=torch.bfloat16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# فكشن تطبعلك عدد الترينبل باراميترز\n",
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(print_number_of_trainable_model_parameters(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACDJ1qqzi4ve",
        "outputId": "c5aeeedb-5a3f-4c3e-8f87-3d0d5cc0230f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable model parameters: 354823168\n",
            "all model parameters: 354823168\n",
            "percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD4eX57bDttA",
        "outputId": "aca833e0-4618-40af-8b6d-4f7d0f03c7fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The predicted next word is: &\n"
          ]
        }
      ],
      "source": [
        "# Let's predict the next word for a given sentence in old model.\n",
        "sentence = 'i have haigh blood'\n",
        "device = \"cpu\"\n",
        "\n",
        "tokens = tokenizer(sentence, return_tensors='pt').to(device)\n",
        "\n",
        "# Get the prediction\n",
        "prediction = model.generate(**tokens)\n",
        "\n",
        "# Get the id of the predicted token\n",
        "\n",
        "predicted_id = prediction.argmax(-1).item()\n",
        "\n",
        "# Decode the token\n",
        "predicted_token = tokenizer.decode([predicted_id])\n",
        "\n",
        "print(f'The predicted next word is: {predicted_token}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "1ddb079da7f8404b94c2b5104f79f3ee",
            "5330843df3ff471d9e3810c4ef80e834",
            "ad0a866c4a144715bc3e083a0b52e679",
            "11d64fb77ffb4749858198f4352831fd",
            "cbc7b6868e5246f085e339edfcd2b3f9",
            "b5dda01a4c764d55a9da7c77efdfd5ce",
            "b984970dbfb24c3db9afa6bd0a8bbaf1",
            "5478c20270f447008d388f8161788d9a",
            "4243b92f4f2043c7add045308da08ac6",
            "b859289262f84455877ceb77ef4d8a90",
            "c5841a18fdf644559300d67b990620d4",
            "5d727bc25bd94e648c9e0b5ed2e8ce61",
            "902018300606446abaf8bbc862114427",
            "718752b7e8c44f17835c676ebf5c54ef",
            "0940d892df434947a9aa45ae37497767",
            "ee286107a9ec456b8a2940c3104f7229",
            "c2d36458f10840a08ecc05100d7bca2b",
            "4679996ddcd644fb8150906f884d6e5d",
            "3670c594042f4a55bb5674d00c2489c9",
            "17f9c2c46a034203a2ecfb9ca55308e0",
            "8db6c14495f44a38bb5d70ab6d356881",
            "a7a2fe5b4a1144fea1034edf3c75d532",
            "3a6b2aff707a4749862b114f060301f9",
            "90383bd099404fb4b0e5573848816f1d",
            "e20e9d819add4d91b7f8db568e6426da",
            "0b3abea7bb2d47cfa0d45ef3382722a5",
            "380bd1fcea194738be9ef7252d3be05e",
            "01b95017065346778b761452493cf32e",
            "939ed4c54b64440d980411b47b3cc5fd",
            "52fedafdf7d94d4eade105c11e94c88b",
            "0bf0ac3002c943d29afbec3d5dbb05e5",
            "0c9d59eb43b74dfeb7e20035fc60f9ac",
            "449bb5eddadd4c0198c3c9b534564031"
          ]
        },
        "id": "AooECo1pXdnl",
        "outputId": "6422adfc-e170-4514-cfea-dab6ef1f2bd4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ddb079da7f8404b94c2b5104f79f3ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/3.37k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d727bc25bd94e648c9e0b5ed2e8ce61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/214M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a6b2aff707a4749862b114f060301f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/796239 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# fine tune\n",
        "\n",
        "from datasets import load_dataset\n",
        "#  حملت البيانات\n",
        "dataset = load_dataset(\"health360/Healix-V1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnwtAgTuYA7I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#  هنا ما اخذ كل البيانات\n",
        "# اخذ فقط عشره بالميه منها\n",
        "# Calculate the number of examples\n",
        "num_examples = len(dataset['train'])\n",
        "\n",
        "num_small = num_examples//20\n",
        "\n",
        "# Generate random indices\n",
        "# و استعمل الراندوم جويس حته يختار انديكسات تكون من الداتا الجبيره\n",
        "# بس عددها ما يتخطى العشره بالميه\n",
        "indices = np.random.choice(num_examples, num_small, replace=False)\n",
        "\n",
        "# Select the randomly chosen examples\n",
        "smaller_dataset = dataset['train'].select(indices)\n",
        "# smaller_dataset = dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODbcRlDUYPld"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "#  و هنا بس نضف التيكست\n",
        "def clean_text(example):\n",
        "  text = example['text'].replace(\"### Input:\", '')\n",
        "  text = text.replace(\"### Response:\", '')\n",
        "  text = text.replace(\"\\n\", '')\n",
        "  return {'text': text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "16c47aed8e4040c0bc3c20659895f247",
            "adfa8e09352240ebb44db4326b583137",
            "e9d75f24a98444b5a4cf5cfea0092a2c",
            "3056155326f046a68ed8c8de1522cda0",
            "4d7d795b437e43a6a1e6167371d6c7a1",
            "e89c9c363dc5459eb437d1eee24a8c08",
            "b66b0e0c7b414651b1d2ce852960e570",
            "04b9c738f09e47e594c4a6650cc61d17",
            "5eb4b38d179c48bf947fbe4bd6547ba2",
            "75c17f2fec46477191926cb53afceedc",
            "48be4e835c2b4d75afd34eb966cc63c9"
          ]
        },
        "id": "UWLkUy8DYSx-",
        "outputId": "eb239c35-cb7a-4764-bb9c-9fe26b7b5552"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16c47aed8e4040c0bc3c20659895f247",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/39811 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "smaller_dataset = smaller_dataset.map(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbdhd_EedOhb"
      },
      "outputs": [],
      "source": [
        "# 796239 full data\n",
        "# 79623 -10%\n",
        "# 159247 -5%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIsH3xLPYaCZ",
        "outputId": "341343bc-ec31-44d4-8787-d0dc5233f6f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39811"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(smaller_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D-XUar1YU_a",
        "outputId": "50f88624-4be6-449e-fd56-3aed878bf328"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'how are bioengineered skin substitutes categorized?- bioengineered skin substitutes can be categorized based on the composition of the source material (synthetic versus biologic, human versus animal), intended duration (permanent versus temporary), intended tissue to be replaced (epidermal versus dermal), and number of layers (single versus bilaminate).'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smaller_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "4608003549744ffa8377a30ba8558d01",
            "756383140caf424fbd2bff438e9dc7fb",
            "7c8391c06b7a419c8d8a09b36177551a",
            "9f2b0eb377d3488dbb7ca3bdcf9886eb",
            "c0e0eba637fb4f5c95c3069f89591084",
            "c20500bfee404bbbbfa1d582761407a2",
            "39e9bb41e3444e4b8323b50fcb723d01",
            "ff9482c16d984107af8d2cdad8815e6c",
            "bda0553c6f124d71be3d665a65a7313b",
            "d821df5e8d0241a7978929db8f0947b2",
            "fe77699ad11f448bbe5e497a3850c061"
          ]
        },
        "id": "V4NLildCYW87",
        "outputId": "fcb35c64-e06a-43c1-f4ec-72c8a646888c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4608003549744ffa8377a30ba8558d01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/39811 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 39811\n",
              "})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # Tokenize the examples\n",
        "    output = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    # Make sure the labels are the same as the input ids\n",
        "    output[\"labels\"] = output[\"input_ids\"].copy()\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_dataset = smaller_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwL8GusCZqDY"
      },
      "outputs": [],
      "source": [
        "#num_rows: 398119"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCJFT0bFZcPi"
      },
      "outputs": [],
      "source": [
        "# spliting\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_data, val_data = train_test_split(tokenized_dataset, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3-zuKmMZcJj"
      },
      "outputs": [],
      "source": [
        "# Now, you can create separate datasets for training and validation\n",
        "train_dataset = Dataset.from_dict(train_data)\n",
        "val_dataset = Dataset.from_dict(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0xkglzHfqWB",
        "outputId": "c9884c7d-78f6-4702-8945-3a361604c1d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 31848\n",
              "})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZYzl3R22cWq",
        "outputId": "bcd77165-d4b2-4d7b-a39f-ba4c89be61b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 7963\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUzTVNUVbzea"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Graduation_Models/Question_Answering_Model/res\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=1,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"/content/drive/MyDrive/Graduation_Models/Question_Answering_Model/log\",\n",
        "    learning_rate=2e-5,\n",
        "\n",
        "     evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "\n",
        "    fp16=True,\n",
        "    logging_steps=100,\n",
        "    optim=\"adamw_torch\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c-LgbCaZckC"
      },
      "outputs": [],
      "source": [
        "# Define the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "0xWnA6M3Zcfp",
        "outputId": "f1d50c5f-e905-4184-cec8-f6856aad615e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='191161' max='199055' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [191161/199055 2:06:00 < 31:09, 4.22 it/s, Epoch 4.80/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='199055' max='199055' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [199055/199055 2:40:00, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.586400</td>\n",
              "      <td>1.468190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=199055, training_loss=0.3090007614009643, metrics={'train_runtime': 9603.5306, 'train_samples_per_second': 20.727, 'train_steps_per_second': 20.727, 'total_flos': 4.621562918731776e+16, 'train_loss': 0.3090007614009643, 'epoch': 5.0})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Start training\n",
        "# resume_from_checkpoint=True\n",
        "trainer.train(resume_from_checkpoint=True)\n",
        "# start 1:23 - 4 first epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "GONZz5uRme4Q",
        "outputId": "5bbd8717-fe58-4269-8968-95297dfd793c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='996' max='996' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [996/996 02:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.5388340950012207,\n",
              " 'eval_runtime': 124.9435,\n",
              " 'eval_samples_per_second': 63.733,\n",
              " 'eval_steps_per_second': 7.972,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6HQIpotCZccB"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "model_ = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/Graduation_Models/Question_Answering_Model/res/checkpoint-199055\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# فكشن تطبعلك عدد الترينبل باراميترز\n",
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(print_number_of_trainable_model_parameters(model_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hl6_Lc6j50y",
        "outputId": "f4936d4c-3133-4bc1-9e9f-564afb205c33"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable model parameters: 354823168\n",
            "all model parameters: 354823168\n",
            "percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXA46h_6ZcUY",
        "outputId": "8f88b2de-7162-4dd3-a775-16fffac9374d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The generated answer is: What are the symptoms of pneumonia?symptoms of pneumonia can include fever, cough, shortness of breath, chest pain, and fatigue.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What are the symptoms of pneumonia?\"\n",
        "device = \"cpu\"\n",
        "\n",
        "# Tokenize the input prompt\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "# Define generation parameters\n",
        "max_length = 100\n",
        "num_return_sequences = 1\n",
        "top_k = 50  # Adjust this parameter for top-k sampling if needed\n",
        "top_p = 0.9  # Adjust this parameter for nucleus sampling if needed\n",
        "\n",
        "# Generate the output answer\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=max_length,\n",
        "    num_return_sequences=num_return_sequences,\n",
        "    top_k=top_k,\n",
        "    top_p=top_p,\n",
        "    temperature=1.0  # Adjust temperature if needed\n",
        ")\n",
        "\n",
        "# Decode the generated answer\n",
        "generated_answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(f'The generated answer is: {generated_answer}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next word prediction"
      ],
      "metadata": {
        "id": "K5PjimMoiJOy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DmVI-FKLiKZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WdHnp-PKKpn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzTw32arKKlB"
      },
      "outputs": [],
      "source": [
        "data_ = pd.read_csv('/content/drive/MyDrive/all_data.csv',index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pbC9C-2KKgp"
      },
      "outputs": [],
      "source": [
        "# pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "kAxMBkp7Kio8",
        "outputId": "800a2eca-d882-45fd-854e-ea48ebd04159"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           LLM Output\n",
              "104  A patient with a history of 3-5 years and multigenic tests showed Luminal B-like characteristics, including HER2 negativity, ER positivity, and Endocrine therapy. However, for those with HER2 overexpression, Cytotoxic Oxics and anti-HER2 therapy are recommended. In cases with Ki-67 ≥ 20-29%, or PgR low/negative, and high recurrence risk, Cytotoxic Oxics or most therapies are suitable. Patients with Luminal B-like features and HER2 overexpression, Cytotoxic Oxics and anti-HER2 therapy are recommended, particularly for those with HER2 amplification. In patients with negative ER and PgR, Cytotoxic Oxics with 80% overlap between Triple-negative subtypes are suitable. A minimum of 3-5 years of more than 20% positivity is recommended in some cases."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56586c80-c0dc-43ef-b25e-4f56690467b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LLM Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>A patient with a history of 3-5 years and multigenic tests showed Luminal B-like characteristics, including HER2 negativity, ER positivity, and Endocrine therapy. However, for those with HER2 overexpression, Cytotoxic Oxics and anti-HER2 therapy are recommended. In cases with Ki-67 ≥ 20-29%, or PgR low/negative, and high recurrence risk, Cytotoxic Oxics or most therapies are suitable. Patients with Luminal B-like features and HER2 overexpression, Cytotoxic Oxics and anti-HER2 therapy are recommended, particularly for those with HER2 amplification. In patients with negative ER and PgR, Cytotoxic Oxics with 80% overlap between Triple-negative subtypes are suitable. A minimum of 3-5 years of more than 20% positivity is recommended in some cases.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56586c80-c0dc-43ef-b25e-4f56690467b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56586c80-c0dc-43ef-b25e-4f56690467b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56586c80-c0dc-43ef-b25e-4f56690467b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data_[104:105]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"LLM Output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"A patient with a history of 3-5 years and multigenic tests showed Luminal B-like characteristics, including HER2 negativity, ER positivity, and Endocrine therapy. However, for those with HER2 overexpression, Cytotoxic Oxics and anti-HER2 therapy are recommended. In cases with Ki-67 \\u2265 20-29%, or PgR low/negative, and high recurrence risk, Cytotoxic Oxics or most therapies are suitable. Patients with Luminal B-like features and HER2 overexpression, Cytotoxic Oxics and anti-HER2 therapy are recommended, particularly for those with HER2 amplification. In patients with negative ER and PgR, Cytotoxic Oxics with 80% overlap between Triple-negative subtypes are suitable. A minimum of 3-5 years of more than 20% positivity is recommended in some cases.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data_[104:105]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gidMg0ZOKikP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-7tIxxeMKigU"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM ,pipeline\n",
        "\n",
        "\n",
        "model_name = \"microsoft/DialoGPT-medium\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# فكشن تطبعلك عدد الترينبل باراميترز\n",
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(print_number_of_trainable_model_parameters(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64RVgkeVkPID",
        "outputId": "5108cba3-82b0-4f3c-ea9d-e55aabdde434"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable model parameters: 354823168\n",
            "all model parameters: 354823168\n",
            "percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE5aBOArKicY",
        "outputId": "20e5cc61-79ed-4ad2-f2f2-7b58df3173d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20023"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Determine the number of rows to select for 20% sample\n",
        "sample_size = int(len(data_) * 0.6)\n",
        "\n",
        "# Randomly select rows indices\n",
        "sampled_indices = data_.sample(n=sample_size, random_state=42).index\n",
        "\n",
        "# Get the corresponding rows from the original DataFrame\n",
        "data_sampled = data_.loc[sampled_indices]\n",
        "\n",
        "len(data_sampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oP9fn1hKxK9"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "R-eqwPZvKxHb",
        "outputId": "036292a4-4f4d-4dc7-93c0-f13c3ad59e38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          LLM Output\n",
              "29945                                                                                                                                                                                                                                                                                                                                                                                                                                 In studies with censored data, linear survival curves are commonly used to display percentage survival (or freedom from a complication) on the x-axis and time on the y-axis. The curve drops as each study patient dies or gets the complication, and if there are few patients, it may be possible to see individual deaths.\n",
              "11836                                                                                                                                                                                                                                                                      MRI reveals characteristics of most regulating spatial expression of proteins involved in cartilage in ous tumors ors: intermediate to low signal intensity on T1-weighted and weighted ed and high signal intensity on T2- also expressed in chondroma fibroma.\" \\n\\nNote: This sentence is extracted from the given text, which contains medical information related to MRI characteristics of proteins in cartilage-related tumors ors. It is suitable for fine-tuning a medical model\n",
              "31161                                                                                                                                                  Morbid jealousy, commonly associated with alcohol abuse, is a major contributor to the frequency of wife battering and is present in 35% of men and 31% of women who abuse a commonest motivator for homicide, according to studies conducted in 1982 and 1990. Delusional jealousy, often accompanied by violence, is more often vented on the partner than on the supposed rival, especially in cases of alcohol abuse, and is a common factor in homicide data from Detroit in 1972. In some cases, morbid homicide data suggests that jealousy is justified, but ultimately motivated by sexual jealousy.\n",
              "9048   n most cases of relapsed ALL, there is a clear clonal relationship between the diagnostic karyotype and that of the original karyotype at the time of diagnosis, with approximately 94% of patients with pre-B ALL and 71% of patients with T-cell ALL exhibiting such relationships. By analyzing patterns of genomic copy number abnormalities, it is clear that CNAs were either present at low levels at diagnosis and then selected for at relapse or newly acquired on the basis of new genomic alterations after initial induction therapy. Only a minority of cases have no change in their genomic copy number abnormalities, with the rest exhibiting either a secondary leukemia emic clone or a leukemia emia that arose from an initial leukemia\n",
              "566                                                                                                                                                                                                                                                                                                                                                  study has shown that patients with one receptor or high-grade tumors have been associated with a particular genetic signature that predicts improved response to neoadjuvant chemotherapy. The incorporation of genomic analyses in the clinical setting allows for the identification of molecular predictors of response to a given treatment and provides insight into the underlying mechanisms of response"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-751116ac-2041-4b5e-b547-bb8aa0ad9762\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LLM Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29945</th>\n",
              "      <td>In studies with censored data, linear survival curves are commonly used to display percentage survival (or freedom from a complication) on the x-axis and time on the y-axis. The curve drops as each study patient dies or gets the complication, and if there are few patients, it may be possible to see individual deaths.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11836</th>\n",
              "      <td>MRI reveals characteristics of most regulating spatial expression of proteins involved in cartilage in ous tumors ors: intermediate to low signal intensity on T1-weighted and weighted ed and high signal intensity on T2- also expressed in chondroma fibroma.\" \\n\\nNote: This sentence is extracted from the given text, which contains medical information related to MRI characteristics of proteins in cartilage-related tumors ors. It is suitable for fine-tuning a medical model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31161</th>\n",
              "      <td>Morbid jealousy, commonly associated with alcohol abuse, is a major contributor to the frequency of wife battering and is present in 35% of men and 31% of women who abuse a commonest motivator for homicide, according to studies conducted in 1982 and 1990. Delusional jealousy, often accompanied by violence, is more often vented on the partner than on the supposed rival, especially in cases of alcohol abuse, and is a common factor in homicide data from Detroit in 1972. In some cases, morbid homicide data suggests that jealousy is justified, but ultimately motivated by sexual jealousy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9048</th>\n",
              "      <td>n most cases of relapsed ALL, there is a clear clonal relationship between the diagnostic karyotype and that of the original karyotype at the time of diagnosis, with approximately 94% of patients with pre-B ALL and 71% of patients with T-cell ALL exhibiting such relationships. By analyzing patterns of genomic copy number abnormalities, it is clear that CNAs were either present at low levels at diagnosis and then selected for at relapse or newly acquired on the basis of new genomic alterations after initial induction therapy. Only a minority of cases have no change in their genomic copy number abnormalities, with the rest exhibiting either a secondary leukemia emic clone or a leukemia emia that arose from an initial leukemia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>study has shown that patients with one receptor or high-grade tumors have been associated with a particular genetic signature that predicts improved response to neoadjuvant chemotherapy. The incorporation of genomic analyses in the clinical setting allows for the identification of molecular predictors of response to a given treatment and provides insight into the underlying mechanisms of response</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-751116ac-2041-4b5e-b547-bb8aa0ad9762')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-751116ac-2041-4b5e-b547-bb8aa0ad9762 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-751116ac-2041-4b5e-b547-bb8aa0ad9762');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-af153711-88b3-4912-8ddf-69136e1d1057\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af153711-88b3-4912-8ddf-69136e1d1057')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-af153711-88b3-4912-8ddf-69136e1d1057 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data_sampled[100:105]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"LLM Output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"MRI reveals characteristics of most regulating spatial expression of proteins involved in cartilage in ous tumors ors: intermediate to low signal intensity on T1-weighted and weighted ed and high signal intensity on T2- also expressed in chondroma fibroma.\\\" \\n\\nNote: This sentence is extracted from the given text, which contains medical information related to MRI characteristics of proteins in cartilage-related tumors ors. It is suitable for fine-tuning a medical model\",\n          \" study has shown that patients with one receptor or high-grade tumors have been associated with a particular genetic signature that predicts improved response to neoadjuvant chemotherapy. The incorporation of genomic analyses in the clinical setting allows for the identification of molecular predictors of response to a given treatment and provides insight into the underlying mechanisms of response\",\n          \"Morbid jealousy, commonly associated with alcohol abuse, is a major contributor to the frequency of wife battering and is present in 35% of men and 31% of women who abuse a commonest motivator for homicide, according to studies conducted in 1982 and 1990. Delusional jealousy, often accompanied by violence, is more often vented on the partner than on the supposed rival, especially in cases of alcohol abuse, and is a common factor in homicide data from Detroit in 1972. In some cases, morbid homicide data suggests that jealousy is justified, but ultimately motivated by sexual jealousy.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "data_sampled[100:105]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I14KnQVkKxC9",
        "outputId": "e60186c2-6f93-46a5-f223-100f86646967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.arrow_dataset.Dataset'>\n",
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 20023\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_function(text):\n",
        "    # Convert the text to a string if it's not already\n",
        "    text = str(text)\n",
        "    # Tokenize the text\n",
        "    output = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    # Make sure the labels are the same as the input ids\n",
        "    output[\"labels\"] = output[\"input_ids\"].copy()\n",
        "\n",
        "    return output\n",
        "\n",
        "# Extract the text column from your DataFrame\n",
        "texts = data_sampled[\"LLM Output\"].tolist()\n",
        "\n",
        "# Tokenize the text using the custom function\n",
        "tokenized_data = [tokenize_function(text) for text in texts]\n",
        "\n",
        "# Combine the tokenized data into a single Dataset\n",
        "tokenized_dataset_1 = Dataset.from_dict({key: [item[key] for item in tokenized_data] for key in tokenized_data[0]})\n",
        "\n",
        "# Print the structure of the resulting dataset\n",
        "print(type(tokenized_dataset_1))\n",
        "print(tokenized_dataset_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1Z51gBgKw8N"
      },
      "outputs": [],
      "source": [
        "# spliting\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_data, val_data = train_test_split(tokenized_dataset_1, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1ieCEBkKwyG"
      },
      "outputs": [],
      "source": [
        "# Now, you can create separate datasets for training and validation\n",
        "train_dataset = Dataset.from_dict(train_data)\n",
        "val_dataset = Dataset.from_dict(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfqnI3H4LKQm",
        "outputId": "35a5fd23-d44b-4341-e074-215fe91f98fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 16018\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmVA899BLKMh",
        "outputId": "7cfa1c10-9b79-4b30-90f3-153ebb8255a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 4005\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cBqEAbqLKJJ"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Graduation_Models/Next_word_model/output\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=1,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"/content/drive/MyDrive/Graduation_Models/Next_word_model/Log\",\n",
        "    learning_rate=2e-5,\n",
        "    fp16=True,\n",
        "    logging_steps=100,\n",
        "\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "\n",
        "    optim=\"adamw_torch\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KL4KhOVcLKFI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "2LTCZ-NXLVfS",
        "outputId": "7008e8e2-2137-4009-ac7f-1ab20a0ebc8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80090' max='80090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [80090/80090 : < :, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=80090, training_loss=0.0, metrics={'train_runtime': 17.7557, 'train_samples_per_second': 4510.673, 'train_steps_per_second': 4510.673, 'total_flos': 1.859490965618688e+16, 'train_loss': 0.0, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Start training\n",
        "# resume_from_checkpoint=True\n",
        "trainer.train(resume_from_checkpoint=True)\n",
        "# start 2:30 - 3:30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww0uRpE0LVcK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "900f2b4c-0dfe-4fb0-8127-f9c6e89830ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='501' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [501/501 00:50]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 2.053778886795044,\n",
              " 'eval_runtime': 51.698,\n",
              " 'eval_samples_per_second': 77.469,\n",
              " 'eval_steps_per_second': 9.691,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju9G7svFLVYa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RRQeW8t3D7j9"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model__ = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/Graduation_Models/Next_word_model/output/checkpoint-80090\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# فكشن تطبعلك عدد الترينبل باراميترز\n",
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(print_number_of_trainable_model_parameters(model__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzH7LGHgkdRK",
        "outputId": "bec5a516-b5a7-4e72-b6dd-5a8662890a0f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable model parameters: 354823168\n",
            "all model parameters: 354823168\n",
            "percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW2tvotcD7r5",
        "outputId": "1ed782d7-3afe-4c3e-e27a-e59724e3d265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted next word is:  disease\n"
          ]
        }
      ],
      "source": [
        "# Let's predict the next word for a given sentence in old model.\n",
        "# sentence = \"The patient was diagnosed with a rare autoimmune disease characterized by atypical\"\n",
        "# sentence = \"In the patient's medical chart, the doctor noted a history of chronic\"\n",
        "# sentence = \"Patient's symptoms require additional tests for conclusive\"\n",
        "sentence = 'i have willnes'\n",
        "device = \"cpu\"\n",
        "tokens = tokenizer(sentence, return_tensors='pt').to(device)\n",
        "\n",
        "# Get the prediction\n",
        "prediction = model(**tokens )\n",
        "\n",
        "# Get the id of the predicted token\n",
        "predicted_id = prediction.logits[...,-1,:].argmax(-1).item()\n",
        "\n",
        "# Decode the token\n",
        "predicted_token = tokenizer.decode([predicted_id])\n",
        "\n",
        "print(f'The predicted next word is: {predicted_token}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarazation model"
      ],
      "metadata": {
        "id": "Sy64G6Kqivia"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SAUqRTyMiwcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT8Zo9ZXXXhe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDXOFmk7eRXh"
      },
      "outputs": [],
      "source": [
        "model_name='google/flan-t5-base'\n",
        "# هنا حملت المودل بس لاحظ استعملت خاصيه ال quantization\n",
        "#  و استعملت الbfloat16 حته اقلل حجم المودل للنص\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1UWrf2r0H3o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_udJX8uejV-",
        "outputId": "e3a02ded-3a74-411b-f076-e8cfa4c28639"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('com/tokenizer_config.json',\n",
              " 'com/special_tokens_map.json',\n",
              " 'com/spiece.model',\n",
              " 'com/added_tokens.json',\n",
              " 'com/tokenizer.json')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.save_pretrained('com')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5Ps8dN4ejGP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYwAQQN5XXTb",
        "outputId": "7bf4bb2b-6dc7-4d17-f520-9c84dadfd26f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable model parameters: 247577856\n",
            "all model parameters: 247577856\n",
            "percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# فكشن تطبعلك عدد الترينبل باراميترز\n",
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(print_number_of_trainable_model_parameters(original_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwlYp_JDb-Bu"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484,
          "referenced_widgets": [
            "2b0117aab63c4d15ae1f91f499d27c60",
            "3044db10758c4a2f9e7a62ddcb564f3a",
            "ca16af109e5e4102acb34e98c425c77c",
            "cc92244a678145beb8000bdd5b1e3916",
            "33d0df03c8754b8da4529fa4ef64140b",
            "b997225a01f845ae82afd01d7e3f5972",
            "13a6c57d38974803b5b8f03701205aec",
            "626d1e8e4bc749b28a7e63f00b0b66a0",
            "5c6ca2b640054f66be7f32f7c0ac12e4",
            "00a7bec419db42428380445b81fabaf2",
            "8369dfca8dca43d0a7ed50e12ba9c845",
            "39d3e2874f1540ca9c212dc594085d23",
            "31cd3b10a033406f853c108f43bf70b0",
            "363d78c85dc84df2999df7fe593b72b9",
            "215ed01a759748c9b3414b24c82e9e7d",
            "0c849cada360446aa7c2b57c284b76b7",
            "b709f87d19b04842a9ceb4c432e68bde",
            "76f73ad5ef7d42c68905a56f00bc8dbc",
            "8006a9c371b14645b8cc7f390aab67b6",
            "46b2f6d01fcf42678fa9723c1293cb50",
            "b2d6372db6f74792956d21620e519cbb",
            "9e00904944764ad885b8b92aecda08f6",
            "680b19981912400bbcddc3cf5ecac4b5",
            "3a8dfb9f810044639a04c524417d8bdb",
            "3e29b804f36e4924b84437bce915aebd",
            "1a24428a1b594aa39f6bb852a5ca8623",
            "619d43497b1b452b962c5311ba3aae3f",
            "1e97491842e1424a8872a82515bcb54b",
            "3e5250191e464853814e267208d10d31",
            "6e4cb8be67a14bdca2d848f25477076d",
            "02d80d2e2b9c469fb09ee41162248779",
            "ed848ea7a8224200b6c59227fdbf9caf",
            "d5b40a56512e4517a98b005497d3ed74",
            "4d4a840d97d24328bb9f0f066467289f",
            "edbd1f9c7b774337b9a1ac748961bf1d",
            "bdde5e20686b4bd1a447b9439c9a0f5c",
            "f00c9c26b1ba4386932255aa6eab097c",
            "f993211994604cbaa8be7abe093a0b4b",
            "4889446040464aca8e51c5d33cee7562",
            "4c9129ce09074f05880b5d8576f19b31",
            "11d0c60a0dff4774befa55e90b360b10",
            "d558285010774a9da6fd5a45e8a024d0",
            "e6385fef8ba34e4b85ff9682808d3f20",
            "f5b2e07f12774223acbc91756643a911",
            "980645574d3e463b8fb5c1ecb97fa414",
            "5c9f843710614a5490a221865aee6745",
            "2173320277be4ae888c17e8d5841eb83",
            "79061ea8ffa4400686000b2a819510e6",
            "81b02a201b1d43dab1b0e87bf1b0656e",
            "cab7be0799df436185e832941c71e03d",
            "b1f63831e0e6464580202e314ae83a33",
            "ed59aab2684e409397d0d64f549760da",
            "7b65478461b84167ae504b2da51e9970",
            "2c9b2f2e5892489f8ed35e0e114e4924",
            "81af66c84ba448c4aa7385c2c55cd621",
            "43cd52e55c77466c9468e76f51829622",
            "19e307375cc34203ac909b8640643e2a",
            "10dcebca7c7946aaa035b19d34a8ca55",
            "bac4a4538db045edbb6bda2c67809929",
            "996ea8045cb64676926186e996515653",
            "53fe51771a964e349579b1672812c295",
            "61ae61b563954056a1f05bec5e5fa9de",
            "f3b8cbc56288480c98a0c86e24b995ca",
            "07bd730930fc4d4f826ede92fb0bc1ae",
            "0da5b189b39449a9bc1b7400190e157f",
            "04e9d3215a514430bf93a5b3127e5161",
            "dfde9a9adf22479ca194cfef835d2c03",
            "67e33f8b9c6b485d83eb9afb27f291ee",
            "3b4460c74cc447fe826174911b0ed178",
            "59b0fd1521dc4b6bac1c6b0e44931a92",
            "b852ba2d840d4b548be85eb44dd3c9b1",
            "d661f4ba7d444ee8b538d0bd5e772324",
            "d54cafa071144068a1b5ea3d76f0c7e7",
            "d1f74ce18b42427e922a3bfe76e81001",
            "cb6482c62df9403fb0fc0eaac30d29da",
            "112927de12ce47f1a630f03d26b3574b",
            "3cee14a7284c44bcbdec3bf6ee7381a1"
          ]
        },
        "id": "-3P2XgNbbuLI",
        "outputId": "2e06a514-7f08-41ad-aab8-7a9ebe9ebeaa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b0117aab63c4d15ae1f91f499d27c60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.65k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39d3e2874f1540ca9c212dc594085d23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "680b19981912400bbcddc3cf5ecac4b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/442k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d4a840d97d24328bb9f0f066467289f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "980645574d3e463b8fb5c1ecb97fa414",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43cd52e55c77466c9468e76f51829622",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfde9a9adf22479ca194cfef835d2c03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 12460\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "\n",
        "dataset = load_dataset(huggingface_dataset_name)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyN-yIGWy4SK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_GLB3W9cLV0",
        "outputId": "6a79f3f8-b12f-4688-ec9d-e936b57aebf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Summarize the following conversation.\n",
            "\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "\n",
            "Summary:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "#Person1#: I'm thinking of upgrading my computer.\n"
          ]
        }
      ],
      "source": [
        "# نستعمل الزيرو شوت بحيث مننطي للمودل اي مساعده مجرد جمله و نكله لخص\n",
        "\n",
        "\n",
        "# اختار انديكس عشوائي\n",
        "index = 200\n",
        "# اختار نص و التلخيص مالته\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    original_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=200,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "3488869452da4e82921ed7412c30f3a6",
            "52c65eea7cd24beda9a79d22ea60e6f4",
            "3336f5a0947b40d08c8aecc3cdd8a719",
            "7e913b084d3a40958b4af8b5cf13dfdf",
            "90e692c703be41f18f92eb8991779ffb",
            "107e768814bb44cb8c728f82bce5a79f",
            "ddfa9816230b4164886ff4cd364e0732",
            "e1531448e93d46eb9fb6bb0b34630c5e",
            "34af7f5ef24e4e80ad6970321df73784",
            "6dbe2b0c0b2244f7bc62bbd82186a271",
            "788da1af22cb4883ba83813aa15f435e",
            "e857e2e1273b4a959dfda1cb2fc9236f",
            "9fb2c61ac8fc4c28a09caabcea2ccae0",
            "3a53622f8363408e8d5b8f34c917d36f",
            "e27d1fd226c84639b4d08040d234a432",
            "fdc0b1f0db5447d1b2e34d44534093ce",
            "5c4844ac481045cab44c9a9cd4ef23ae",
            "d59fbdafbb1c477e867c36efa4e0f439",
            "59ff17f98722487d97da180d432ec305",
            "653abfad400344dc983f5ad09268a598",
            "ea5713b29c3041c79a2298c7a64261df",
            "f24ad4ca01be493a800b54a1b806a809",
            "ca2d933f2bab4dd5b6e02dc4a8ebe00f",
            "e0be6e83843b41d0b2e189e95b347297",
            "ae11c99a455243038c69e4f86d3bca0c",
            "cd6f66902d9149bebe761d58c6e9578d",
            "5811ca7c8f69453eb21928355442a3d1",
            "dbf9998ba3d14ceda8810792e5c3ff76",
            "0153fefebaeb48d88a67234a09f599d6",
            "c0e2c43e4c45439a8260b2e05a18586e",
            "17497911da44471fa16f230a83e4cd02",
            "b24927a0755c448abe23bc1b2eb81c0e",
            "20dbafdf71114e319977156b682ddb7c"
          ]
        },
        "id": "It3mk4e5er6F",
        "outputId": "8428b067-5d85-415b-a414-1f312a49ef0a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3488869452da4e82921ed7412c30f3a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e857e2e1273b4a959dfda1cb2fc9236f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca2d933f2bab4dd5b6e02dc4a8ebe00f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# هاي الفكشن هي تسوي البيانات بالشكل المطلوب حيث بيها الجمله او التعلميات للمودل و ايضا بعدها تخلي\n",
        "# الدايلوك اوالجمله الي اريد الخصها و بعدها كلمه summary\n",
        "def tokenize_function(example):\n",
        "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
        "    end_prompt = '\\n\\nSummary: '\n",
        "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n",
        "    # و هنا خلا بيها الانبوت ايديس و ليبلز\n",
        "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    return example\n",
        "\n",
        "# The dataset actually contains 3 diff splits: train, validation, test.\n",
        "# The tokenize_function code is handling all data across all splits in batches.\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxHpXajAertr",
        "outputId": "2f479542-6700-40ab-d06d-ec177f38130a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'labels'],\n",
              "        num_rows: 12460\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'labels'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'labels'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# اول شي الترين و التيست و الفال هذني موجودات بالداتا الاصليه ما لعبت بيهن\n",
        "# و ايضا بدلت او مسحت الاعمده القديمه و خليت الجديده الي هي الانبوت ايدس و ليبلز\n",
        "# و طبعا الفكشن سوت لكلشي توكينايز و كلشي تمام للمودل\n",
        "tokenized_datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LnTaLKvxsFf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PSYRGJkerbA"
      },
      "outputs": [],
      "source": [
        "# هنا اخذ جزء من الداتا مو كلها علمود الوقت\n",
        "# tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)\n",
        "tokenized_datasets = tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CO8096FcLNc",
        "outputId": "6bb805d9-3cb0-4e51-ebbe-2712305e3285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes of the datasets:\n",
            "Training: (12460, 2)\n",
            "Validation: (500, 2)\n",
            "Test: (1500, 2)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shapes of the datasets:\")\n",
        "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
        "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
        "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
        "\n",
        "# print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoHUdLK15Zmp"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "266UrI2wfu8Y"
      },
      "outputs": [],
      "source": [
        "# هسه اجيت اسوي فاين تيون ف طريقه التدريب ب هاكنك فيس ك التالي تاخذ ترينر و تريننك اركيومنت\n",
        "\n",
        "\n",
        "# هنا الاوت بوت اي المودل وين يتخزن\n",
        "output_dir = f'/content/drive/MyDrive/Graduation_Models/Summary_Model/output'\n",
        "logging_dir = f'/content/drive/MyDrive/Graduation_Models/Summary_Model/Log'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=1,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=logging_dir,\n",
        "    learning_rate=2e-5,\n",
        "    logging_steps=100,\n",
        "    save_strategy ='epoch',\n",
        "    optim=\"adamw_torch\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    # Customize this function based on your evaluation needs\n",
        "    return {\"perplexity\": p.metrics[\"eval_loss\"]}\n",
        "\n",
        "# Create a data collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # Set to True if you are using a masked language model\n",
        ")\n",
        "\n",
        "# هنا اجيب انطيته بيانات التدريب و الاختبار و المودل و الاركيومنت\n",
        "trainer = Trainer(\n",
        "    model=original_model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbgqKl0Kfur_",
        "outputId": "d9c021b1-36cc-44ef-a786-8bd729c38bac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='52780' max='62300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [52780/62300 2:29:43 < 1:06:59, 2.37 it/s, Epoch 4.24/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>31600</td>\n",
              "      <td>0.033000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31700</td>\n",
              "      <td>0.048800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31800</td>\n",
              "      <td>0.036600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31900</td>\n",
              "      <td>0.039900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>0.030400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32100</td>\n",
              "      <td>0.031900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32200</td>\n",
              "      <td>0.033400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32300</td>\n",
              "      <td>0.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32400</td>\n",
              "      <td>0.030500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32500</td>\n",
              "      <td>0.038400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32600</td>\n",
              "      <td>0.035900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32700</td>\n",
              "      <td>0.034000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32800</td>\n",
              "      <td>0.032400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32900</td>\n",
              "      <td>0.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33000</td>\n",
              "      <td>0.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33100</td>\n",
              "      <td>0.037100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33200</td>\n",
              "      <td>0.033900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33300</td>\n",
              "      <td>0.035300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33400</td>\n",
              "      <td>0.033200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33500</td>\n",
              "      <td>0.036700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33600</td>\n",
              "      <td>0.035600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33700</td>\n",
              "      <td>0.040800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33800</td>\n",
              "      <td>0.034400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33900</td>\n",
              "      <td>0.045500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>0.049100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34100</td>\n",
              "      <td>0.040200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34200</td>\n",
              "      <td>0.039800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34300</td>\n",
              "      <td>0.041300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34400</td>\n",
              "      <td>0.040900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34500</td>\n",
              "      <td>0.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34600</td>\n",
              "      <td>0.030600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34700</td>\n",
              "      <td>0.034700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34800</td>\n",
              "      <td>0.043000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34900</td>\n",
              "      <td>0.033900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35000</td>\n",
              "      <td>0.038500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35100</td>\n",
              "      <td>0.032900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35200</td>\n",
              "      <td>0.039000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35300</td>\n",
              "      <td>0.042900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35400</td>\n",
              "      <td>0.037000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35500</td>\n",
              "      <td>0.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35600</td>\n",
              "      <td>0.036600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35700</td>\n",
              "      <td>0.033100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35800</td>\n",
              "      <td>0.033500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35900</td>\n",
              "      <td>0.041500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36000</td>\n",
              "      <td>0.034900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36100</td>\n",
              "      <td>0.039000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36200</td>\n",
              "      <td>0.031800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36300</td>\n",
              "      <td>0.035900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36400</td>\n",
              "      <td>0.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36500</td>\n",
              "      <td>0.037200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36600</td>\n",
              "      <td>0.039800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36700</td>\n",
              "      <td>0.044700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36800</td>\n",
              "      <td>0.038400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36900</td>\n",
              "      <td>0.035500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37000</td>\n",
              "      <td>0.032800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37100</td>\n",
              "      <td>0.033700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37200</td>\n",
              "      <td>0.033800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37300</td>\n",
              "      <td>0.030200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37400</td>\n",
              "      <td>0.039500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37500</td>\n",
              "      <td>0.043000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37600</td>\n",
              "      <td>0.037200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37700</td>\n",
              "      <td>0.034300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37800</td>\n",
              "      <td>0.037800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37900</td>\n",
              "      <td>0.039000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38000</td>\n",
              "      <td>0.043500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38100</td>\n",
              "      <td>0.038200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38200</td>\n",
              "      <td>0.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38300</td>\n",
              "      <td>0.039000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38400</td>\n",
              "      <td>0.032900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38500</td>\n",
              "      <td>0.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38600</td>\n",
              "      <td>0.034000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38700</td>\n",
              "      <td>0.044600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38800</td>\n",
              "      <td>0.040400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38900</td>\n",
              "      <td>0.036700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39000</td>\n",
              "      <td>0.040600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39100</td>\n",
              "      <td>0.039300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39200</td>\n",
              "      <td>0.033900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39300</td>\n",
              "      <td>0.042200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39400</td>\n",
              "      <td>0.037300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39500</td>\n",
              "      <td>0.036000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39600</td>\n",
              "      <td>0.036200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39700</td>\n",
              "      <td>0.039700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39800</td>\n",
              "      <td>0.037800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39900</td>\n",
              "      <td>0.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>0.034200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40100</td>\n",
              "      <td>0.038900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40200</td>\n",
              "      <td>0.037200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40300</td>\n",
              "      <td>0.039600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40400</td>\n",
              "      <td>0.038300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40500</td>\n",
              "      <td>0.030300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40600</td>\n",
              "      <td>0.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40700</td>\n",
              "      <td>0.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40800</td>\n",
              "      <td>0.036100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40900</td>\n",
              "      <td>0.036800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41000</td>\n",
              "      <td>0.038300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41100</td>\n",
              "      <td>0.045300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41200</td>\n",
              "      <td>0.043100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41300</td>\n",
              "      <td>0.040800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41400</td>\n",
              "      <td>0.038700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41500</td>\n",
              "      <td>0.034700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41600</td>\n",
              "      <td>0.035800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41700</td>\n",
              "      <td>0.031800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41800</td>\n",
              "      <td>0.038600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41900</td>\n",
              "      <td>0.035100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42000</td>\n",
              "      <td>0.034800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42100</td>\n",
              "      <td>0.043400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42200</td>\n",
              "      <td>0.043500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42300</td>\n",
              "      <td>0.038200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42400</td>\n",
              "      <td>0.028800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42500</td>\n",
              "      <td>0.038000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42600</td>\n",
              "      <td>0.031300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42700</td>\n",
              "      <td>0.043000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42800</td>\n",
              "      <td>0.035700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42900</td>\n",
              "      <td>0.031000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43000</td>\n",
              "      <td>0.035100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43100</td>\n",
              "      <td>0.036500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43200</td>\n",
              "      <td>0.033000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43300</td>\n",
              "      <td>0.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43400</td>\n",
              "      <td>0.035400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43500</td>\n",
              "      <td>0.035000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43600</td>\n",
              "      <td>0.038400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43700</td>\n",
              "      <td>0.037100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43800</td>\n",
              "      <td>0.033300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43900</td>\n",
              "      <td>0.036100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44000</td>\n",
              "      <td>0.040800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44100</td>\n",
              "      <td>0.042700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44200</td>\n",
              "      <td>0.033700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44300</td>\n",
              "      <td>0.030600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44400</td>\n",
              "      <td>0.031000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44500</td>\n",
              "      <td>0.036400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44600</td>\n",
              "      <td>0.041200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44700</td>\n",
              "      <td>0.036500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44800</td>\n",
              "      <td>0.038700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44900</td>\n",
              "      <td>0.037900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45000</td>\n",
              "      <td>0.036900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45100</td>\n",
              "      <td>0.032500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45200</td>\n",
              "      <td>0.031900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45300</td>\n",
              "      <td>0.032200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45400</td>\n",
              "      <td>0.032800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45500</td>\n",
              "      <td>0.047300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45600</td>\n",
              "      <td>0.031400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45700</td>\n",
              "      <td>0.038000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45800</td>\n",
              "      <td>0.038500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45900</td>\n",
              "      <td>0.038000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46000</td>\n",
              "      <td>0.040600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46100</td>\n",
              "      <td>0.031400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46200</td>\n",
              "      <td>0.039700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46300</td>\n",
              "      <td>0.041500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46400</td>\n",
              "      <td>0.036800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46500</td>\n",
              "      <td>0.039900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46600</td>\n",
              "      <td>0.035300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46700</td>\n",
              "      <td>0.038300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46800</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46900</td>\n",
              "      <td>0.045200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47000</td>\n",
              "      <td>0.034000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47100</td>\n",
              "      <td>0.036400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47200</td>\n",
              "      <td>0.034300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47300</td>\n",
              "      <td>0.029300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47400</td>\n",
              "      <td>0.035700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47500</td>\n",
              "      <td>0.036800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47600</td>\n",
              "      <td>0.031700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47700</td>\n",
              "      <td>0.039600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47800</td>\n",
              "      <td>0.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47900</td>\n",
              "      <td>0.038800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48000</td>\n",
              "      <td>0.033000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48100</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48200</td>\n",
              "      <td>0.044400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48300</td>\n",
              "      <td>0.038700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48400</td>\n",
              "      <td>0.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48500</td>\n",
              "      <td>0.039500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48600</td>\n",
              "      <td>0.039900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48700</td>\n",
              "      <td>0.035700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48800</td>\n",
              "      <td>0.040800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48900</td>\n",
              "      <td>0.036000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49000</td>\n",
              "      <td>0.040600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49100</td>\n",
              "      <td>0.040700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49200</td>\n",
              "      <td>0.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49300</td>\n",
              "      <td>0.042100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49400</td>\n",
              "      <td>0.037100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49500</td>\n",
              "      <td>0.041500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49600</td>\n",
              "      <td>0.030600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49700</td>\n",
              "      <td>0.037400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49800</td>\n",
              "      <td>0.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49900</td>\n",
              "      <td>0.040200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50000</td>\n",
              "      <td>0.038100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50100</td>\n",
              "      <td>0.031500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50200</td>\n",
              "      <td>0.034300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50300</td>\n",
              "      <td>0.043300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50400</td>\n",
              "      <td>0.038100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50500</td>\n",
              "      <td>0.035700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50600</td>\n",
              "      <td>0.033600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50700</td>\n",
              "      <td>0.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50800</td>\n",
              "      <td>0.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50900</td>\n",
              "      <td>0.039200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51000</td>\n",
              "      <td>0.033700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51100</td>\n",
              "      <td>0.044000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51200</td>\n",
              "      <td>0.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51300</td>\n",
              "      <td>0.034100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51400</td>\n",
              "      <td>0.039700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51500</td>\n",
              "      <td>0.042100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51600</td>\n",
              "      <td>0.036200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51700</td>\n",
              "      <td>0.037300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51800</td>\n",
              "      <td>0.036700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51900</td>\n",
              "      <td>0.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52000</td>\n",
              "      <td>0.039200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52100</td>\n",
              "      <td>0.039600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52200</td>\n",
              "      <td>0.038400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52300</td>\n",
              "      <td>0.034600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52400</td>\n",
              "      <td>0.035100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52500</td>\n",
              "      <td>0.038000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52600</td>\n",
              "      <td>0.034800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52700</td>\n",
              "      <td>0.030200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# هسه نبدي ندرب\n",
        "#ساعه  و نص للايبوك الواحد\n",
        "trainer.train(resume_from_checkpoint=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnANxjcl2xoo"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h--6tF-Y8GRF"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/Graduation_Models/Summary_Model/output/checkpoint-30000\"\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    raise ValueError(f\"Checkpoint not found at {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "zrTpcKTr6THy",
        "outputId": "4599201c-0163-4dd3-cdc6-53d83d727cb7"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ea500d8a758a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fsdp_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         ):\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;31m# If model was re-initialized, put it on the right device and update self.model_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(self, resume_from_checkpoint, model)\u001b[0m\n\u001b[1;32m   2109\u001b[0m                 \u001b[0;31m# workaround for FSDP bug https://github.com/pytorch/pytorch/issues/82963\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2110\u001b[0m                 \u001b[0;31m# which takes *args instead of **kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2111\u001b[0;31m                 \u001b[0mload_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2112\u001b[0m                 \u001b[0;31m# release memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2113\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2136\u001b[0m                 )\n\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2138\u001b[0;31m         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2139\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                     \u001b[0mchild_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                     \u001b[0mchild_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal_state_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m             \u001b[0;31m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m                 \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'assign_to_params_buffers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m             module._load_from_state_dict(\n\u001b[0m\u001b[1;32m   2121\u001b[0m                 local_state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n\u001b[1;32m   2122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m                     error_msgs.append(f'While copying the parameter named \"{key}\", '\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train(resume_from_checkpoint=checkpoint_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsak8c9pfuV7"
      },
      "outputs": [],
      "source": [
        "instruct_model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/Graduation_Models/Summary_Model/output/checkpoint-12460\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWkMufX4vu-v"
      },
      "outputs": [],
      "source": [
        "original_model = original_model.to('cuda')\n",
        "instruct_model = instruct_model.to('cuda')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EhkAeLFyb33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_HK1F8Rk7Pn",
        "outputId": "a733813d-6892-4625-ac2a-5e10c645744b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "ORIGINAL MODEL:\n",
            "#Person1#: I'm thinking of upgrading my computer.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INSTRUCT MODEL:\n",
            "#Person1#: Have you considered upgrading your system? #Person2#: Yes, but I'm not sure what exactly I would need. #Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising. #Person2#: That would be a definite bonus. #Person1#: You might also want to upgrade your hardware because it is pretty outdated now. #Person2#: How can we do that? #Person1#: You'd probably need a faster processor, more memory and a faster modem. Do you have a CD-ROM drive? #Person2#: No. #Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on CDs. #Person2#: That sounds\n"
          ]
        }
      ],
      "source": [
        "# هنا اختبرت المودل و اقدرته ورا الفاين تيون\n",
        "index = 200\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "human_baseline_summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize this conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "top_p = 0.5\n",
        "top_k = 3\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "input_ids = input_ids.to('cuda')\n",
        "\n",
        "\n",
        "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1,))\n",
        "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
        "print(dash_line)\n",
        "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue-NlDjlwIZ7",
        "outputId": "a40209a6-5ff9-4559-f5c3-1df097f919cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(human_baseline_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM5efVWLwSmF",
        "outputId": "1596f178-5f53-4f9f-9042-b6105c588ec2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(original_model_text_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxLvKnIPwOBw",
        "outputId": "742e430a-f1c4-43c6-c1dd-d2a50bb01efc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "692"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(instruct_model_text_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_pW8aw3odRQ"
      },
      "outputs": [],
      "source": [
        "import evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAoeYOONo_dT",
        "outputId": "677d2ca3-81da-4ff7-9453-dfa953c9bedd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.23.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=ca8c4fa0777842dc3dfda36233de5f622e87bc7c0d89d02d69aa5e7abe94f4d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmdPTVPAk7LH"
      },
      "outputs": [],
      "source": [
        "# Evaluate the Model Quantitatively (with ROUGE Metric)\n",
        "\n",
        "rouge = evaluate.load('rouge')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "001JlC6app6u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "3pOaIsARk7F1",
        "outputId": "98383a37-9789-40d0-b2f8-4130fc3e0b0e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-90c27112-5800-4146-8386-c46e29e99650\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_summaries</th>\n",
              "      <th>original_model_summaries</th>\n",
              "      <th>instruct_model_summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
              "      <td>[ purpose ] this memo should go out as an intr...</td>\n",
              "      <td>[ purpose ] [ purpose ] [ subject to this new ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In order to prevent employees from wasting tim...</td>\n",
              "      <td>[ purpose ] this memo should go out as an intr...</td>\n",
              "      <td>[ purpose ] [ purpose ] [ subject to this new ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
              "      <td>[ purpose ] this memo should go out as an intr...</td>\n",
              "      <td>[ purpose ] [ purpose ] [ subject to this new ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#Person2# arrives late because of traffic jam....</td>\n",
              "      <td>a lot of traffic jams are causing pollution in...</td>\n",
              "      <td>#Person1#: You're finally here! What took so l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
              "      <td>a lot of traffic jams are causing pollution in...</td>\n",
              "      <td>#Person1#: You're finally here! What took so l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
              "      <td>a lot of traffic jams are causing pollution in...</td>\n",
              "      <td>#Person1#: You're finally here! What took so l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
              "      <td>Summary: a couple of girls who have a separati...</td>\n",
              "      <td>Summary: Kate and Hero are getting divorced. K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
              "      <td>Summary: a couple of girls who have a separati...</td>\n",
              "      <td>Summary: Kate and Hero are getting divorced. K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
              "      <td>Summary: a couple of girls who have a separati...</td>\n",
              "      <td>Summary: Kate and Hero are getting divorced. K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
              "      <td>a great party. #Person1#: Happy Birthday, this...</td>\n",
              "      <td>Brian, Brian, may I have a pleasure to have a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90c27112-5800-4146-8386-c46e29e99650')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90c27112-5800-4146-8386-c46e29e99650 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90c27112-5800-4146-8386-c46e29e99650');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7fa73819-04e9-4915-8754-046749aeb218\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fa73819-04e9-4915-8754-046749aeb218')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7fa73819-04e9-4915-8754-046749aeb218 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                            human_baseline_summaries  \\\n",
              "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
              "1  In order to prevent employees from wasting tim...   \n",
              "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
              "3  #Person2# arrives late because of traffic jam....   \n",
              "4  #Person2# decides to follow #Person1#'s sugges...   \n",
              "5  #Person2# complains to #Person1# about the tra...   \n",
              "6  #Person1# tells Kate that Masha and Hero get d...   \n",
              "7  #Person1# tells Kate that Masha and Hero are g...   \n",
              "8  #Person1# and Kate talk about the divorce betw...   \n",
              "9  #Person1# and Brian are at the birthday party ...   \n",
              "\n",
              "                            original_model_summaries  \\\n",
              "0  [ purpose ] this memo should go out as an intr...   \n",
              "1  [ purpose ] this memo should go out as an intr...   \n",
              "2  [ purpose ] this memo should go out as an intr...   \n",
              "3  a lot of traffic jams are causing pollution in...   \n",
              "4  a lot of traffic jams are causing pollution in...   \n",
              "5  a lot of traffic jams are causing pollution in...   \n",
              "6  Summary: a couple of girls who have a separati...   \n",
              "7  Summary: a couple of girls who have a separati...   \n",
              "8  Summary: a couple of girls who have a separati...   \n",
              "9  a great party. #Person1#: Happy Birthday, this...   \n",
              "\n",
              "                            instruct_model_summaries  \n",
              "0  [ purpose ] [ purpose ] [ subject to this new ...  \n",
              "1  [ purpose ] [ purpose ] [ subject to this new ...  \n",
              "2  [ purpose ] [ purpose ] [ subject to this new ...  \n",
              "3  #Person1#: You're finally here! What took so l...  \n",
              "4  #Person1#: You're finally here! What took so l...  \n",
              "5  #Person1#: You're finally here! What took so l...  \n",
              "6  Summary: Kate and Hero are getting divorced. K...  \n",
              "7  Summary: Kate and Hero are getting divorced. K...  \n",
              "8  Summary: Kate and Hero are getting divorced. K...  \n",
              "9  Brian, Brian, may I have a pleasure to have a ...  "
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# هنا اخذ بس عشر سامبلات و قيم بيهن المودل الاصلي بدون تعديل و قيم ايضا المودل الي سويتله فاين تيون\n",
        "# و ب روج طبعا\n",
        "\n",
        "dialogues = dataset['test'][0:10]['dialogue']\n",
        "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "\n",
        "for _, dialogue in enumerate(dialogues):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "\n",
        "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s02ikz44k6_m",
        "outputId": "12076152-cd63-4dad-b3f1-ddd33e3747b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.14495877038053528, 'rouge2': 0.025132885690161234, 'rougeL': 0.10734854191439931, 'rougeLsum': 0.10598143808643898}\n",
            "INSTRUCT MODEL:\n",
            "{'rouge1': 0.16403334487739019, 'rouge2': 0.05360793615254001, 'rougeL': 0.13371414071699528, 'rougeLsum': 0.13496962262442147}\n"
          ]
        }
      ],
      "source": [
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9gzJ-d-qZqM",
        "outputId": "46f200d3-634d-4091-84fd-d6f76a4ad203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Absolute percentage improvement of INSTRUCT MODEL over ORIGINAL MODEL\n",
            "rouge1: 1.91%\n",
            "rouge2: 2.85%\n",
            "rougeL: 2.64%\n",
            "rougeLsum: 2.90%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of INSTRUCT MODEL over ORIGINAL MODEL\")\n",
        "# نسبه مئويه لمقدار التقدم عن المودل العادي بدون فاين تيون\n",
        "improvement = (np.array(list(instruct_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(instruct_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcRrK_FdqXv-"
      },
      "outputs": [],
      "source": [
        "# peft\n",
        "# هسه حنبدي نشتغل ب لورا و الي تجمد الويتس مال مودل و تجيب ابعاد اصغرr\n",
        "# و تدربهم ع بيانات الفاين تيون و بعدها ترجع و تدمجهن بالمودل الجديد\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    # و هذا الدايمنشن الي كلنه يكون بين ال8 و 32\n",
        "    r=32, # Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    # هذا نوع التاسك\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etvMwEUfqTXk",
        "outputId": "48453036-fb4a-4ea2-80c0-9750d7ab1a48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable model parameters: 3538944\n",
            "all model parameters: 251116800\n",
            "percentage of trainable model parameters: 1.41%\n"
          ]
        }
      ],
      "source": [
        "# هنا انطيته المودل مالتي حته يجمده و انطيته اعدادات لورا حته يضبطها\n",
        "peft_model = get_peft_model(original_model,\n",
        "                            lora_config)\n",
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIx6NPapqS6J"
      },
      "outputs": [],
      "source": [
        "# هسه اجيت اسوي فاين تيون ف طريقه التدريب ب هاكنك فيس ك التالي تاخذ ترينر و تريننك اركيومنت\n",
        "\n",
        "\n",
        "# هنا الاوت بوت اي المودل وين يتخزن\n",
        "output_dir = f'/content/drive/MyDrive/Graduation_Models/Summary_Model/peftmodel/output'\n",
        "logging_dir = f'/content/drive/MyDrive/Graduation_Models/Summary_Model/peftmodel/log'\n",
        "\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=1,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=logging_dir,\n",
        "    learning_rate=2e-5,\n",
        "    save_strategy ='epoch',\n",
        "    logging_steps=100,\n",
        "\n",
        "    optim=\"adamw_torch\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # و هنا الاركيومنت مال التدريب\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=output_dir,\n",
        "#     learning_rate=1e-5,\n",
        "#     # ايبوك واحد هنا\n",
        "#     num_train_epochs=4,\n",
        "#     warmup_steps=100,\n",
        "#     weight_decay=0.01,\n",
        "\n",
        "\n",
        "#     logging_steps=100,\n",
        "#     max_steps=1\n",
        "# )\n",
        "\n",
        "\n",
        "# هنا اجيب انطيته بيانات التدريب و الاختبار و المودل و الاركيومنت\n",
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "MowNvbefqSdn",
        "outputId": "a5e1581f-02d7-4fef-a003-9fc86486319a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='12460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   25/12460 00:07 < 1:05:22, 3.17 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-8d72851eaa1f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpeft_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0maccelerate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrelease_memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_wrapped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelease_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_wrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m                 if (\n\u001b[0;32m-> 1872\u001b[0;31m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mfloating_point_ops\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m             \u001b[0mreturn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_return_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3461\u001b[0;31m         \u001b[0mloss_without_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturn_loss\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfloating_point_ops\u001b[0;34m(self, input_dict, exclude_embeddings)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0monly_trainable\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m                 \u001b[0mWhether\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0mexclude_embeddings\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mnum_parameters\u001b[0;34m(self, only_trainable, exclude_embeddings)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0;31m# show warning only if it won't be shown in `create_extended_attention_mask_for_decoder`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m                 warnings.warn(\n\u001b[1;32m    994\u001b[0m                     \u001b[0;34m\"The `device` argument is deprecated and will be removed in v5 of Transformers.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0;31m# show warning only if it won't be shown in `create_extended_attention_mask_for_decoder`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m                 warnings.warn(\n\u001b[0m\u001b[1;32m    994\u001b[0m                     \u001b[0;34m\"The `device` argument is deprecated and will be removed in v5 of Transformers.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m                 )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "peft_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PJ04g-3rzlA"
      },
      "outputs": [],
      "source": [
        "# هنا حتدمج المودل مالتك ويا المودل مال لورا\n",
        "\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "# هنا حملت المودل الاصلي بدون اي تعديل و التوكينايزر مالته\n",
        "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"Falconsai/medical_summarization\", torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Falconsai/medical_summarization\")\n",
        "\n",
        "# رجعت هنا انطيته المودل الاصلي و بعدها رابط المودل مال لورا او الرابط مالته و ايضا سويت كوانتيزيشن\n",
        "# و اخر باراميتر خليته فولز لان بعد ما اريد اسوي عليه فاين تيون يعني اريد هسه اسويله ديبلوي\n",
        "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
        "                                       '/content/Peft/checkpoint-500',\n",
        "                                       torch_dtype=torch.bfloat16,\n",
        "                                       is_trainable=False)\n",
        "# بالتالي الترنبل باراميتر يصير 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM8ehVYasQn2",
        "outputId": "081c7152-a1c1-4f36-dc2a-45ad1f6083ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable model parameters: 0\n",
            "all model parameters: 61686272\n",
            "percentage of trainable model parameters: 0.00%\n"
          ]
        }
      ],
      "source": [
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqGk7BNIsQTi",
        "outputId": "0305c56b-a6bf-495a-a9ca-346af51a8e37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "ORIGINAL MODEL:\n",
            "Summary: a new software program is coming out on Cds.results:the following conversation is discussed.results:the following conversation is a discussion.results:the following conversation is a discussion.results:the following conversation was a discussion.results:the following conversation was a discussion.results:the following conversation was a discussion.results:the following conversation was a discussion.conclusions:the following conversation is a few.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INSTRUCT MODEL:\n",
            "#Person1#: Have you considered upgrading your system? #Person1#: Yes, but I'm not sure what exactly I would need. #Person1#: You could consider adding a painting program to your software. #Person1#: You might also want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "PEFT MODEL: Summary: a summary of the following conversation is presented. #Person1#: Have you considered upgrading your system? #Person1#: Yes, but I'm not sure what exactly I would need. #Person1#: You could consider adding a painting program to your software. #Person1#: You might also want to upgrade your hardware because it is pretty outdated now. #Person1#: No. #Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n"
          ]
        }
      ],
      "source": [
        "# تقييم حسب الانسان\n",
        "index = 200\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "baseline_human_summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
        "print(dash_line)\n",
        "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'PEFT MODEL: {peft_model_text_output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "-RbbipPGsPtL",
        "outputId": "4efac9d0-726f-4c08-852b-8c6f761a486e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b04aa769-69ea-4f5f-8b57-58c7ce1fa2d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_summaries</th>\n",
              "      <th>original_model_summaries</th>\n",
              "      <th>instruct_model_summaries</th>\n",
              "      <th>peft_model_summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
              "      <td>[ purpose ] this memo should go out as an intr...</td>\n",
              "      <td>[ purpose ] [ purpose ] [ subject to this new ...</td>\n",
              "      <td>[ purpose ] this memo should go out as an intr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In order to prevent employees from wasting tim...</td>\n",
              "      <td>[ purpose ] this memo should go out as an intr...</td>\n",
              "      <td>[ purpose ] [ purpose ] [ subject to this new ...</td>\n",
              "      <td>[ purpose ] this memo should go out as an intr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
              "      <td>[ purpose ] this memo should go out as an intr...</td>\n",
              "      <td>[ purpose ] [ purpose ] [ subject to this new ...</td>\n",
              "      <td>[ purpose ] this memo should go out as an intr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#Person2# arrives late because of traffic jam....</td>\n",
              "      <td>a lot of traffic jams are causing pollution in...</td>\n",
              "      <td>#Person1#: You're finally here! What took so l...</td>\n",
              "      <td>Summary: The following conversation was conduc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
              "      <td>a lot of traffic jams are causing pollution in...</td>\n",
              "      <td>#Person1#: You're finally here! What took so l...</td>\n",
              "      <td>Summary: The following conversation was conduc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
              "      <td>a lot of traffic jams are causing pollution in...</td>\n",
              "      <td>#Person1#: You're finally here! What took so l...</td>\n",
              "      <td>Summary: The following conversation was conduc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
              "      <td>Summary: a couple of girls who have a separati...</td>\n",
              "      <td>Summary: Kate and Hero are getting divorced. K...</td>\n",
              "      <td>Summary: a short summary of the discussion is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
              "      <td>Summary: a couple of girls who have a separati...</td>\n",
              "      <td>Summary: Kate and Hero are getting divorced. K...</td>\n",
              "      <td>Summary: a short summary of the discussion is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
              "      <td>Summary: a couple of girls who have a separati...</td>\n",
              "      <td>Summary: Kate and Hero are getting divorced. K...</td>\n",
              "      <td>Summary: a short summary of the discussion is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
              "      <td>a great party. #Person1#: Happy Birthday, this...</td>\n",
              "      <td>Brian, Brian, may I have a pleasure to have a ...</td>\n",
              "      <td>a great party. a great party. a great party. a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b04aa769-69ea-4f5f-8b57-58c7ce1fa2d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b04aa769-69ea-4f5f-8b57-58c7ce1fa2d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b04aa769-69ea-4f5f-8b57-58c7ce1fa2d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99c9686f-99d3-4813-bb17-3902e589b54e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99c9686f-99d3-4813-bb17-3902e589b54e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99c9686f-99d3-4813-bb17-3902e589b54e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                            human_baseline_summaries  \\\n",
              "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
              "1  In order to prevent employees from wasting tim...   \n",
              "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
              "3  #Person2# arrives late because of traffic jam....   \n",
              "4  #Person2# decides to follow #Person1#'s sugges...   \n",
              "5  #Person2# complains to #Person1# about the tra...   \n",
              "6  #Person1# tells Kate that Masha and Hero get d...   \n",
              "7  #Person1# tells Kate that Masha and Hero are g...   \n",
              "8  #Person1# and Kate talk about the divorce betw...   \n",
              "9  #Person1# and Brian are at the birthday party ...   \n",
              "\n",
              "                            original_model_summaries  \\\n",
              "0  [ purpose ] this memo should go out as an intr...   \n",
              "1  [ purpose ] this memo should go out as an intr...   \n",
              "2  [ purpose ] this memo should go out as an intr...   \n",
              "3  a lot of traffic jams are causing pollution in...   \n",
              "4  a lot of traffic jams are causing pollution in...   \n",
              "5  a lot of traffic jams are causing pollution in...   \n",
              "6  Summary: a couple of girls who have a separati...   \n",
              "7  Summary: a couple of girls who have a separati...   \n",
              "8  Summary: a couple of girls who have a separati...   \n",
              "9  a great party. #Person1#: Happy Birthday, this...   \n",
              "\n",
              "                            instruct_model_summaries  \\\n",
              "0  [ purpose ] [ purpose ] [ subject to this new ...   \n",
              "1  [ purpose ] [ purpose ] [ subject to this new ...   \n",
              "2  [ purpose ] [ purpose ] [ subject to this new ...   \n",
              "3  #Person1#: You're finally here! What took so l...   \n",
              "4  #Person1#: You're finally here! What took so l...   \n",
              "5  #Person1#: You're finally here! What took so l...   \n",
              "6  Summary: Kate and Hero are getting divorced. K...   \n",
              "7  Summary: Kate and Hero are getting divorced. K...   \n",
              "8  Summary: Kate and Hero are getting divorced. K...   \n",
              "9  Brian, Brian, may I have a pleasure to have a ...   \n",
              "\n",
              "                                peft_model_summaries  \n",
              "0  [ purpose ] this memo should go out as an intr...  \n",
              "1  [ purpose ] this memo should go out as an intr...  \n",
              "2  [ purpose ] this memo should go out as an intr...  \n",
              "3  Summary: The following conversation was conduc...  \n",
              "4  Summary: The following conversation was conduc...  \n",
              "5  Summary: The following conversation was conduc...  \n",
              "6  Summary: a short summary of the discussion is ...  \n",
              "7  Summary: a short summary of the discussion is ...  \n",
              "8  Summary: a short summary of the discussion is ...  \n",
              "9  a great party. a great party. a great party. a...  "
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# و هنا حيقيم ب روج لل3 مودلات\n",
        "\n",
        "dialogues = dataset['test'][0:10]['dialogue']\n",
        "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "peft_model_summaries = []\n",
        "\n",
        "for idx, dialogue in enumerate(dialogues):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    human_baseline_text_output = human_baseline_summaries[idx]\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "    peft_model_summaries.append(peft_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries, peft_model_summaries))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries', 'peft_model_summaries'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spjyFCtot_dr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyOIS-Z5t_Rj",
        "outputId": "5e0d76b0-f4cf-4149-e329-e7bc3eb7a97b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.14495877038053528, 'rouge2': 0.025132885690161234, 'rougeL': 0.10734854191439931, 'rougeLsum': 0.10598143808643898}\n",
            "INSTRUCT MODEL:\n",
            "{'rouge1': 0.16403334487739019, 'rouge2': 0.05360793615254001, 'rougeL': 0.13371414071699528, 'rougeLsum': 0.13496962262442147}\n",
            "PEFT MODEL:\n",
            "{'rouge1': 0.11845824916588851, 'rouge2': 0.027788553320893507, 'rougeL': 0.08328314146211482, 'rougeLsum': 0.08144067107488592}\n"
          ]
        }
      ],
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "peft_model_results = rouge.compute(\n",
        "    predictions=peft_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)\n",
        "print('PEFT MODEL:')\n",
        "print(peft_model_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nga8KZSnuffY",
        "outputId": "6836c2f3-995e-42bf-ec6d-e8ff124b31b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Absolute percentage improvement of PEFT MODEL over ORIGINAL MODEL\n",
            "rouge1: -2.65%\n",
            "rouge2: 0.27%\n",
            "rougeL: -2.41%\n",
            "rougeLsum: -2.45%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of PEFT MODEL over ORIGINAL MODEL\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMjQVyzqulEx",
        "outputId": "bda827e8-a4c9-48e9-a338-d0d4a907d5a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\n",
            "rouge1: -4.56%\n",
            "rouge2: -2.58%\n",
            "rougeL: -5.04%\n",
            "rougeLsum: -5.35%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(instruct_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Second attempt\n"
      ],
      "metadata": {
        "id": "wJ9b7Jfpl_0g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3sln6H9TmDHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wSZ4LG5yl0D",
        "outputId": "07ebd1a1-1747-4fdb-dcc8-d045ab9679e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.1)\n",
            "Collecting py7zr\n",
            "  Downloading py7zr-0.20.8-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.2)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Collecting texttable (from py7zr)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.15.9 (from py7zr)\n",
            "  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n",
            "  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n",
            "  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n",
            "  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli>=1.1.0 (from py7zr)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=f6c2a6433414225f5a275869390134f2cade3fcfa27198b7814c777cb40a2bbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: texttable, brotli, pyzstd, pytesseract, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, dill, rouge-score, py7zr, multiprocess, transformers, datasets\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed brotli-1.1.0 datasets-2.16.1 dill-0.3.7 inflate64-1.0.0 multiprocess-0.70.15 multivolumefile-0.2.3 py7zr-0.20.8 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pytesseract-0.3.10 pyzstd-0.15.9 rouge-score-0.1.2 texttable-1.7.0 transformers-4.37.2\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.11 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.26.1\n"
          ]
        }
      ],
      "source": [
        "# python\n",
        "!pip install pytesseract transformers datasets rouge-score nltk tensorboard py7zr --upgrade\n",
        "! pip install transformers[torch]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R9E19_by324",
        "outputId": "2b80354b-44fc-4f02-8dd2-71cffb507a36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# install git-fls for pushing model and logs to the hugging face hub\n",
        "!sudo apt-get install git-lfs --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "60b930a4911c4335bb8a954e230ef4c6",
            "796d900c06714c0798850e196da28a2f",
            "a3b8f06e57414e1e95840cdc6518840e",
            "78296e6ea223456383d3a359b1648582",
            "2e3fe5b091d14d32bc0718fb3a0048b5",
            "46c4f0c620444f309183958e282294be",
            "8455983be3ee4353838d8decda3eb043",
            "5106ae0435c94f2bb3cb95d373d72dcc",
            "281c7c4e180b4592800b5b1513e21035",
            "1ae62775f0e14e6a9c6b109ab10b598b",
            "02a88a28135c4e02bc1061e2eba43d3a",
            "8e3987655c194bf0b83fa875f663e2af",
            "31a4b03e9de34bb084c5eaa5c357708a",
            "dcdf06eac49d4a30b772c8fdffeaf648"
          ]
        },
        "id": "Aili1VjczEoR",
        "outputId": "13ca4f4c-6fb8-48c7-9143-c9c5edf418ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60b930a4911c4335bb8a954e230ef4c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mh3aG_bP_1vf"
      },
      "outputs": [],
      "source": [
        "dataset_id = \"samsum\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "1718d0684e5348edafba11a6277d3fe0",
            "570df7e7d9fa40b8acbc509c890e42f3",
            "add01881d066452dbae2c9e286a9743d",
            "9faa2dcf35aa4298a3591aa06a60dfa2",
            "ff673c058dbc40f39d202e445ceed193",
            "8a7eadcc9ad74c938e96f65a6fe2a752",
            "201eab74b1ca4eaab692e70d79777d6e",
            "7d6d8ab872db43b5b71951a618e7b094",
            "ee04d884e3ec44a7be9cd6b66e6bf7c7",
            "c7b6919295f04ab28dabc68274e2b964",
            "ccbe48f128ba4c51b86a05ef879a478d",
            "1f4b20e35cd74aa2a08589d0040dd642",
            "e870894093274b4bbfa6912d9999e4a9",
            "3fc8936886ea41489fb2de3882c927dc",
            "49523676e6e149af879d736961ab0de0",
            "0ef19fd5777440aa840653910ae89f93",
            "2bd83a1a1b26480da5b667e70bf66bec",
            "08ba52ec728b4a82943014263b26a995",
            "48ba0e0f9641499ba25de231f3f73166",
            "a5c91d85a09047feab2d35d1454010aa",
            "94beed5c99aa4d8cb875bccae4745208",
            "a8862732ea3640a2acf1b8fa99b93bfb",
            "c151eda3a4d647cebe82f590b3079831",
            "f689204145c44186a9cf3490738d6696",
            "49589a8fa81b4cc6b95cbe06017f12ea",
            "a868d2811814497d85768cb4e55f05df",
            "608a09c5dfd24b37a44b489bdd878121",
            "fd722383ea444ca0a6d345ec5016bdec",
            "29f8783119424bae8af05dc1a0dd44c9",
            "89e3fd3d24354394a8c1c0f0d36fb54f",
            "2c57045ae50f4a669d109c2b63407557",
            "2f4fb5f340e94a17b8488a633150e12a",
            "712f78e6dc0d4d13bf133cca9f3d4f06",
            "4cba93da834c47a6be5a358f0cfa1cb7",
            "ee77f472a22648f882eb1e66ae1c5b2f",
            "d6422003172741a087eb5c455153cdbd",
            "4ddf9ac274b74361bfb3979712f3bbd3",
            "1bd208e88b74454d90fee2d8dc212591",
            "766634a451fd4e38a2365fcaa21dd6c2",
            "e9314de5bcf9405398f35c85ffd02497",
            "0ff29b12cab8490baa7e1a81175f9b9c",
            "1c18c1cf264e4bd8b2dda6051c955eeb",
            "529ad45b99244e1b96914c3c17d3a637",
            "4f22ace5f4ce46ddadfacbe7fa302440",
            "0ef06a8e3f904e759e76feb3ec0a53f4",
            "fda553d382f245389a1488d1d7c35423",
            "aec1fba65521417eb59b7df8362273d4",
            "2dbce7052160435b907f27cd12e5e15d",
            "035f32a3f98b4e91b269c30dddff33fc",
            "e95e132992214ec0a2d3933f3772be9d",
            "ede021b6198542f0946cfa2368c8ae9d",
            "a85106cfcabe47a19329a196efc6dd5b",
            "b9a7826ace8c419799055f5563443768",
            "afa2210f978240aa90a582ca564e01d4",
            "54606ea1d04e4548a36bb8d0a379907f",
            "88859364741b4cebb92fec33bf3ff2dd",
            "dc6a0c89a9b246fb8ac23dea33223cc4",
            "d68c6fa003604eafa4a23072e01cc71e",
            "6c1a348760c04086bcc7eeaaaebb0ea7",
            "24acc03414fe4396815d3a80fb0951fa",
            "ab01223b0dbc4c31a9c6310033de4469",
            "bcf7a2c4c7864dd18bf33f7916a4aec5",
            "40531044e2454eddb163683f3abf832d",
            "8c3374d05ef645be97cd0c42ec29dce1",
            "f917c9c2cc9a44e38b0dcab1385760c6",
            "ab313271c3dd41d18d936f7c1a1825df"
          ]
        },
        "id": "TYjCBJQY_1vf",
        "outputId": "ac28c16d-b73b-40ae-ef9b-e1e738e7de3e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1718d0684e5348edafba11a6277d3fe0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/6.06M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f4b20e35cd74aa2a08589d0040dd642",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/347k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c151eda3a4d647cebe82f590b3079831",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/335k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cba93da834c47a6be5a358f0cfa1cb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ef06a8e3f904e759e76feb3ec0a53f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88859364741b4cebb92fec33bf3ff2dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 14732\n",
            "Test dataset size: 819\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset from the hub\n",
        "dataset = load_dataset(dataset_id)\n",
        "\n",
        "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
        "print(f\"Test dataset size: {len(dataset['test'])}\")\n",
        "\n",
        "# Train dataset size: 14732\n",
        "# Test dataset size: 819"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAdKaAsJ_1vg",
        "outputId": "71cd64df-7418-44d8-b339-9f55ce2be8ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dialogue: \n",
            "Kirsten: yay! got tickets! \r\n",
            "Viola: wot tickets luv?\r\n",
            "Kirsten: Ed's gig!\r\n",
            "Viola: wow. u mean ed sheeran. Lucky!\r\n",
            "Kirsten: I know, so excited!\r\n",
            "Viola: when's that?\r\n",
            "Kirsten: in august. still plenty of time but can't wait already\r\n",
            "Viola: I know, if you're fan it's always like that\r\n",
            "Kirsten: yep. I luv this guy.\n",
            "---------------\n",
            "summary: \n",
            "Kristen got tickets for Ed Sheeran's gig in August.\n",
            "---------------\n"
          ]
        }
      ],
      "source": [
        "from random import randrange\n",
        "\n",
        "\n",
        "sample = dataset['train'][randrange(len(dataset[\"train\"]))]\n",
        "print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
        "print(f\"summary: \\n{sample['summary']}\\n---------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "6ddae43f10d64b7f8397555658121f0e",
            "4b9c4ba1cf024aca85b35db3d6f1fd12",
            "bb0fa2f556b64e25806bb72d3176c66b",
            "dd4c3817521548ed9ca3a52b682f715f",
            "5b4ae80bcac7471baf7b1d194737fc94",
            "4917d9c9cdc1421caee96437501c499e",
            "cc45dc2c954f4abcafd15635cf43e7d4",
            "ed1194662b714e168aaaf00fddde68e7",
            "6759e074076c4477be4991999e8ee2d8",
            "b9116107f437425580b2c4f7aca921c9",
            "0b008410b56e4adabdad4675cfe46f0d",
            "c29c8986c41e456f91443eaf0f341cc8",
            "94ac0f93f6e24f7185795e73988b0892",
            "6790c55ba83642198e38d5f0548826fa",
            "1399b7298441439abedb008a1d2a499e",
            "7382c4db8583484fa9a36c1a597669b3",
            "76c20613dfab4e918643057a8f50a4fc",
            "4a5f491252944ca78804a54042c7f8f1",
            "f6a7cc2d484940038f455ea84e165c53",
            "4fe430fcfd6f4d159c9a61b2fcc5013e",
            "9425238a54464c2c90d40552937de1ec",
            "817a003ebc9c470fb7568ad47d0ffbd3",
            "c90aee6b7c544dc2878769a5b85ce111",
            "440bbd5f759342e787815a37fb0b37bd",
            "949911369f774d24b21fd90273b507f7",
            "74dc5f9d2a1141c082951c20bfb2f6d1",
            "4bf9a5812a914baea90e795fdcf5c5cf",
            "862b2813b5a04bb1ac591f8d368b4490",
            "2ae309c6395143d2a9cdf37e13cefbfe",
            "1c6c6271b1a24836824b57be537dd90f",
            "d79443336db54a27b5089d3f3e04ad3e",
            "4c8badabea7c47aeaacac2e5bd1e3281",
            "71e9ba101bf94cc48eae7afa655db006",
            "130335198c9a45629628b20d0f5cf0ed",
            "f14f1c2d89bd4dd7ab2fb0a30a7d87f1",
            "f749ed0d1204405ea250ecee083b9bfd",
            "a29d6324bde84116ab8f3a09ebaf6e62",
            "536e5c59873244f0aa000bda45bb25d0",
            "fb776f6c122146b28c0668f10ac4ebcb",
            "3bb8ff14aa3d4f39838c301f1ee0416a",
            "c584a3cd635f4582bebb908f2ebfe89e",
            "aa6e69ed870d48c484a5f4ceb302e987",
            "d6afb47279d14f8287807ec7a17cb37b",
            "4c410ffdcc824a598407d32231b30ddd"
          ]
        },
        "id": "FuovzX2e_1vg",
        "outputId": "3a2743da-206d-4baa-c21e-327b582cee0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ddae43f10d64b7f8397555658121f0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c29c8986c41e456f91443eaf0f341cc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c90aee6b7c544dc2878769a5b85ce111",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "130335198c9a45629628b20d0f5cf0ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_id=\"google/flan-t5-base\"\n",
        "\n",
        "# Load tokenizer of FLAN-t5-base\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "a137d3d340474cd4b99e56ddbf8cd3f7",
            "2c9a7f6c6941450b9c9ae962f6031c4b",
            "059f8e49b9c34309bf279b9c34760735",
            "ca3607f541274a84a4cec458b0f302b0",
            "37daab38b76f4293b0bf6ebc8014bbe9",
            "eb1a49d782504145ae07fb5120ab0177",
            "13507665eb85426b86fb90da01a44156",
            "a36ee577dac74779a04c302891d79822",
            "effcd137d2004a5fba17d8a5c0ad1417",
            "9bd9ae5b5eb24bfd9974dc4b2cac5720",
            "ab900c4f5c9e4fb7a080857fab5d830b",
            "7294953c2fb7433191a8af83d6ea633c",
            "c159b94323f1459198281c9a260e6cb7",
            "31b485712e9541a1a1c870511d0a6667",
            "07150b48305646d29003b5e317cfb585",
            "88fd50bb424f4d4d883e3b130ffe1b6c",
            "fe0b0eaf67724caa9a67fd1a205c1cd2",
            "e5422456e435413ab13ebdef0e43ba82",
            "83cda985ef9943ac8dff1ffd02cc3c22",
            "38365f9cf752494caa866d1b78b8e3c5",
            "1efb43ded88149c18448eb6a0187377e",
            "81702897b66b436d8d9fab973bda9c5b"
          ]
        },
        "id": "WznLXsbj_1vg",
        "outputId": "f080c1ae-f20f-44e3-cd32-4a01c337b63e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a137d3d340474cd4b99e56ddbf8cd3f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15551 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max source length: 512\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7294953c2fb7433191a8af83d6ea633c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15551 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max target length: 95\n"
          ]
        }
      ],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "# The maximum total input sequence length after tokenization.\n",
        "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
        "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"dialogue\"], truncation=True), batched=True, remove_columns=[\"dialogue\", \"summary\"])\n",
        "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
        "print(f\"Max source length: {max_source_length}\")\n",
        "\n",
        "# The maximum total sequence length for target text after tokenization.\n",
        "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
        "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"summary\"], truncation=True), batched=True, remove_columns=[\"dialogue\", \"summary\"])\n",
        "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
        "print(f\"Max target length: {max_target_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "d8e4db79831b4b42b25b740ded3e0ca5",
            "52977113936b43bab708ad7a0e0c7b9d",
            "fe6187d30be64991bcc4e6c8a1cdd6c8",
            "20b0bd2aaf1a405ea222d7e1cdd8131f",
            "4dd34de4fbbd448bafc157fbe854d08d",
            "e303730bd54642fc8e3ea824928fcdd8",
            "3ae0a04612cd41678850ccd17839f16b",
            "1429a5eecddc41e8b45144d1f6fbbb1f",
            "32b55e71ab8149d391cf063ac8ce2f41",
            "09453c4acc654e65a4d71c6ed2262007",
            "f69a9a7cf5bc4c7387230302b67388a1",
            "b4ddcecb4afd43fab6a900cedd4fa464",
            "2d303e940e4b4ca1a0486bc852551012",
            "065818c0bf574984ab01398c71e8bc14",
            "043e1adbf8e44b67ba8f615316c27a5b",
            "49cda76610094de7b285b4da1599e74e",
            "7027a1650a6d4540abf3fb265c44b58a",
            "317ef4fdc8af4726870411b53237d05e",
            "e8ed4ff4115840479055db1482deb0db",
            "52ba9540d57241c19b7c013b058fa7dd",
            "6dee748e99d04e8f8cdf3c7aeaf1bdc0",
            "51a8dfbd91664bb59025e4280324886e",
            "6473d24235a640cdba77a0036eb713b0",
            "44c55e4df12f41888fbc8e05fcb23a7f",
            "f4b96b812e9b4df4bf0dc4512d1bb4e4",
            "1b5c6d62f4014a9abe6d7e37c7b60b55",
            "101d13899ca94bcba687d7591740be25",
            "5b3facd0ddf4431e89e0da92eb3c9ce5",
            "df4ff3fb1bb740cc9d979f318ea21239",
            "2b0051918ac4428a87d89432d1e54fab",
            "54326b37fe6547b6a0255b8d465b8b68",
            "07564d92a5214a9d9db895c8917533c2",
            "990263a5f97c4d94a5b639f867020214"
          ]
        },
        "id": "VCGyZdAx_1Xe",
        "outputId": "c991567d-3e39-484e-85f6-a577cd32a9f0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8e4db79831b4b42b25b740ded3e0ca5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4ddcecb4afd43fab6a900cedd4fa464",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6473d24235a640cdba77a0036eb713b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
          ]
        }
      ],
      "source": [
        "def preprocess_function(sample,padding=\"max_length\"):\n",
        "    # add prefix to the input for t5\n",
        "    inputs = [\"summarize: \" + item for item in sample[\"dialogue\"]]\n",
        "\n",
        "    # tokenize inputs\n",
        "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
        "\n",
        "    # Tokenize targets with the `text_target` keyword argument\n",
        "    labels = tokenizer(text_target=sample[\"summary\"], max_length=max_target_length, padding=padding, truncation=True)\n",
        "\n",
        "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
        "    # padding in the loss.\n",
        "    if padding == \"max_length\":\n",
        "        labels[\"input_ids\"] = [\n",
        "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
        "        ]\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=[\"dialogue\", \"summary\", \"id\"])\n",
        "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "20ef14e7fcb14237abe76c8d97ec00fb",
            "0625f14c4ca84ed992ab477fb8d4487e",
            "8cfd59e69aff453d8f9fb296c178381a",
            "2ce3ada4cb644f34832bf3db0593014c",
            "6ac7d1691b4f44578be53d04ea9f086b",
            "92f0dcd7f7f849bcafea98cb57376fcd",
            "a53ac567283f4640a7954fad0ba07416",
            "12c61d3813034d629bcb466959a09dd9",
            "c72c1a487c06439f81e728a5a2c869e2",
            "72474c5970aa4dd085d170c60a2265ba",
            "72211d2a4be34f6197a324587ead5a8e",
            "bdc8bd9f4f7448da8982e5244b146b73",
            "7702f92c0e104f6ebca912f934ed9744",
            "bd8ff7ece8f14f28b4c2bce591caa48f",
            "5bf3504d69e440f2aaa2b0ed3c7fb9d5",
            "5b18bd2378f0451ea460048ac923352e",
            "49f1f7f657b442a8bee0dd7459e550fb",
            "3ac844d6a06a44c2aaefe0a19c1ace13",
            "70ed45d8a5224137b938025796aa302d",
            "028ea5557ce541c495755491a47ef4f8",
            "452ee2bbaf3041198a5c384811f36fc6",
            "ff98371b2e0d4b59893db0b1b77bdeaf",
            "2f8227b8257f42f3b1469f5b03b370b4",
            "53fbcd233f864854a2778a25f18a8741",
            "aeb6448913234958bb822abd6f7b6992",
            "7036ec538e4c44e09b54da9a49251371",
            "fcf76228bca6428caaf5d24a12705170",
            "e740ab0ab02e4a49834b10aee7845dd0",
            "f59b708b60d1464da5dfd1e926ae5277",
            "d91b73c7664746da936aec234c307be7",
            "4c3043cf1b4b4c38b4257b261c63ab36",
            "22c9bb0c556b4858b4ac17dbbf9f0434",
            "2df8459a486f4180b7575f9c03d790b9"
          ]
        },
        "id": "TwznKPPh_1Uw",
        "outputId": "a9f14061-a9da-4c9f-d508-dc2fd5fa4326"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20ef14e7fcb14237abe76c8d97ec00fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdc8bd9f4f7448da8982e5244b146b73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f8227b8257f42f3b1469f5b03b370b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "# huggingface hub model id\n",
        "model_id=\"google/flan-t5-base\"\n",
        "\n",
        "# load model from the hub\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caDoTG_J_1Rj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "4d3bb190cc414a708f5ed69a1664e211",
            "56af26a3425144cc94353769ea26f8e7",
            "73191f88403b43579eb74fee08ed11f2",
            "11f5289efa954f2f9d89417b511686eb",
            "207a4e1abc1d4b4488ce25d96fd7b8e6",
            "ae1518cee5a041fcb3eaab75377b8f77",
            "ce184c0c62a24afda6d33848c19c1d09",
            "d77a0b0723834ddeb6464a74a19b9801",
            "8e05701de95b4aeeaeeb9eac8a4bb6b0",
            "4fa94bd330f04382aeca2de41f2d6adf",
            "bd6e5773310a442585ca507fd940632c"
          ]
        },
        "id": "KwyMn8yf-2gN",
        "outputId": "9bd07d21-8007-400e-fd0b-d0fe273fef4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d3bb190cc414a708f5ed69a1664e211",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import evaluate\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Metric\n",
        "metric = evaluate.load(\"rouge\")\n",
        "\n",
        "# helper function to postprocess text\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJcfHFoE-2dV"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# we want to ignore tokenizer pad token in the loss\n",
        "label_pad_token_id = -100\n",
        "# Data collator\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=label_pad_token_id,\n",
        "    pad_to_multiple_of=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzKeZ4yjDfP8"
      },
      "outputs": [],
      "source": [
        "# peft\n",
        "# هسه حنبدي نشتغل ب لورا و الي تجمد الويتس مال مودل و تجيب ابعاد اصغرr\n",
        "# و تدربهم ع بيانات الفاين تيون و بعدها ترجع و تدمجهن بالمودل الجديد\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    # و هذا الدايمنشن الي كلنه يكون بين ال8 و 32\n",
        "    r=32, # Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    # هذا نوع التاسك\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "6cKhTr2KDfP9",
        "outputId": "e68c6852-1440-4c80-edfc-c3db82449cfe"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'print_number_of_trainable_model_parameters' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-efa5f16792da>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m peft_model = get_peft_model(model,\n\u001b[1;32m      3\u001b[0m                             lora_config)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_number_of_trainable_model_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeft_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'print_number_of_trainable_model_parameters' is not defined"
          ]
        }
      ],
      "source": [
        "# هنا انطيته المودل مالتي حته يجمده و انطيته اعدادات لورا حته يضبطها\n",
        "peft_model = get_peft_model(model,\n",
        "                            lora_config)\n",
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkShmscRDfP-"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfFolder\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "# Hugging Face repository id\n",
        "repository_id = f\"{model_id.split('/')[1]}-{dataset_id}-moh\"\n",
        "\n",
        "# Define training args\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/Graduation_Models/Summary_Model/peftmodel/output',\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    fp16=False, # Overflows with fp16\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=5,\n",
        "    # logging & evaluation strategies\n",
        "    logging_dir=\"/content/drive/MyDrive/Graduation_Models/Summary_Model/peftmodel/log\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=500,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    # metric_for_best_model=\"overall_f1\",\n",
        "    # push to hub parameters\n",
        "    report_to=\"tensorboard\",\n",
        "    # push_to_hub=False,\n",
        "    hub_strategy=\"every_save\",\n",
        "    # hub_model_id=repository_id,\n",
        "    # hub_token=HfFolder.get_token(),\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "peft_trainer = Seq2SeqTrainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "0zdSuZ8xDfP-",
        "outputId": "f7c87fa5-a44f-4a2a-91a6-3dbb3f2e4746"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='253' max='9210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 253/9210 04:05 < 2:25:53, 1.02 it/s, Epoch 0.14/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1843' max='9210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1843/9210 29:56 < 1:59:49, 1.02 it/s, Epoch 1/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.455900</td>\n",
              "      <td>1.412373</td>\n",
              "      <td>46.246600</td>\n",
              "      <td>22.113900</td>\n",
              "      <td>38.553400</td>\n",
              "      <td>42.569700</td>\n",
              "      <td>17.195360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "\n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'base_model.model.encoder.embed_tokens.weight', 'base_model.model.shared.weight', 'base_model.model.decoder.embed_tokens.weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8d72851eaa1f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpeft_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1540\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1943\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1944\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2302\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2303\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m             \u001b[0mstaging_output_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"tmp-{checkpoint_folder}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2378\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstaging_output_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_only_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2886\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m         \u001b[0;31m# Push to the Hub when `save_model` is called by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2950\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trainer.model is not a `PreTrainedModel`, only saving its state dict.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2951\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_safetensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2952\u001b[0;31m                     safetensors.torch.save_file(\n\u001b[0m\u001b[1;32m   2953\u001b[0m                         \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAFE_WEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mserialize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36m_flatten\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfailing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    478\u001b[0m             f\"\"\"\n\u001b[1;32m    479\u001b[0m             \u001b[0mSome\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0mshare\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mlead\u001b[0m \u001b[0mto\u001b[0m \u001b[0mduplicate\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0mon\u001b[0m \u001b[0mdisk\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mdifferences\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mloading\u001b[0m \u001b[0mthem\u001b[0m \u001b[0magain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mfailing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'base_model.model.encoder.embed_tokens.weight', 'base_model.model.shared.weight', 'base_model.model.decoder.embed_tokens.weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            "
          ]
        }
      ],
      "source": [
        "peft_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v0mSYyn0YNq"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfFolder\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "# Hugging Face repository id\n",
        "repository_id = f\"{model_id.split('/')[1]}-{dataset_id}-moh\"\n",
        "\n",
        "# Define training args\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/Graduation_Models/Summary_Model/output',\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    fp16=False, # Overflows with fp16\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=5,\n",
        "    # logging & evaluation strategies\n",
        "    logging_dir=\"/content/drive/MyDrive/Graduation_Models/Summary_Model/Log\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=500,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    # metric_for_best_model=\"overall_f1\",\n",
        "    # push to hub parameters\n",
        "    report_to=\"tensorboard\",\n",
        "    # push_to_hub=False,\n",
        "    hub_strategy=\"every_save\",\n",
        "    # hub_model_id=repository_id,\n",
        "    # hub_token=HfFolder.get_token(),\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "_spYa5O52AJG",
        "outputId": "2454e348-3bb0-443c-e3a4-e0261b5a1a93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9211' max='9210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9210/9210 37:54, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='46' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 46/103 00:51 < 01:05, 0.87 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9210' max='9210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9210/9210 40:24, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.196000</td>\n",
              "      <td>1.374168</td>\n",
              "      <td>47.410900</td>\n",
              "      <td>23.618600</td>\n",
              "      <td>39.638300</td>\n",
              "      <td>43.556700</td>\n",
              "      <td>17.313797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9210, training_loss=0.24027443056386147, metrics={'train_runtime': 2426.5374, 'train_samples_per_second': 30.356, 'train_steps_per_second': 3.796, 'total_flos': 5.048305105187635e+16, 'train_loss': 0.24027443056386147, 'epoch': 5.0})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Start training\n",
        "# epochs\n",
        "#5\t1.196000\t1.374168\t47.410900\t23.618600\t39.638300\t43.556700\t17.313797\n",
        "trainer.train(resume_from_checkpoint=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "6nVWrlb5_hvL",
        "outputId": "c2c94a62-f35e-4964-d1ee-390173576148"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [103/103 02:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.3700677156448364,\n",
              " 'eval_rouge1': 47.4992,\n",
              " 'eval_rouge2': 23.573,\n",
              " 'eval_rougeL': 39.8929,\n",
              " 'eval_rougeLsum': 43.647,\n",
              " 'eval_gen_len': 17.35286935286935,\n",
              " 'eval_runtime': 123.4031,\n",
              " 'eval_samples_per_second': 6.637,\n",
              " 'eval_steps_per_second': 0.835,\n",
              " 'epoch': 5.0}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588,
          "referenced_widgets": [
            "e43531da4524455092193cac61d25f0c",
            "86d9aa72f36f4a3d9c725da56c598467",
            "50afb8e7b35141ce897a66bc0ef47e38",
            "1f90f5faa7c84d4ca4b7e5858a84fa03",
            "09db5f925ff645d38cac9fbcfb064650",
            "d1cdfe91b9dd4e0ab77335c7d843a12a",
            "2e4af274d8a4483abafe2a6aadbecf0d",
            "cc362e9d76204054a20baa63bc636b65",
            "2ab2d6c1fb9d439d9605328a60e93e1f",
            "260155f5cf494627928c518a40dbef90",
            "7999da89e77640d888feeb6214395269",
            "bac00ac8850c4f1f8c7ac2d23029ec9b",
            "9f1764bc402b43d29be700bffeb020c1",
            "42d354296d754b66a39220b6f1cfd104",
            "525e6115c51546a1b5492bbc3d7e84e6",
            "d7e129b11ee14bffb0c638abadbb11ec",
            "b3d2ab6a90f9497bad4f99242fc045be",
            "c4a03fd457b3411f958f659104137113",
            "fdfb80ebc585452c95f78abe4af58c9b",
            "5f09650b6d02499998850bb3a9974e1c",
            "3745414ef0db4eb6bdaab10cb592d77f",
            "766004852afc4115a6ec55ec399d1f9c",
            "49607e900b7b47edbc06f3a477055fd2",
            "1bb77d5d793f4e9abae2e1842346998b",
            "8e5538e3767f4aa587253558aaf1a06c",
            "cdb998d48e6041e2a9f58f9ecb4d89cf",
            "b74e672e982a4bc08c95ff175e974b73",
            "49cd645995e14121aae28bbac56f773a",
            "fe21c9833f88469290146d6a015f9092",
            "a351958c0eb14939aa1e4f6ffb1461f2",
            "8a9d55678bc240a68db44d85de7c27ba",
            "edcb81a499ab4838b623441225d520f0",
            "ffba39a463df4b998d42025b9bb0cc85",
            "a96eec6ff06d41ba9cfadef716e9c277",
            "1c478ee6ae05442f9e212220030f3bde",
            "f65c26534b024dfd82c7db1064ebf187",
            "cf1a158462484a70ae4428974ce2c30d",
            "bfaa2405d48d4a109b24e166bfbe459a",
            "a912666ae603448190b96b80576e50b1",
            "d41ecdefe36244e89a1b2f1809596766",
            "d6571f411c04425d90a963a76ffb4725",
            "44983fe637304f08841c31909ad6d6ef",
            "94f8b43879ac41fab5700a5fe7de446c",
            "1c32e95e87a049e4a8a05ff63fb90252",
            "815bb528ca4c43dca9383e80a3338521",
            "6f6282bec3594f5cafc4cbb02876c575",
            "9a4eb64478ba4bbd91906221b07e065f",
            "1127c8a31fb84a4bb2563f5e5d0a34e7",
            "b8d42535ef334ef9be14535d69d94f4a",
            "f1b3e38e64284e16bf982e13439005ae",
            "d517425b70c7423595b4904ef930ad5a",
            "bfc7d45be8af4b6c8b5173cb2d48bceb",
            "fafcd5509a8747fea9fdb3bf34707640",
            "0386277d4d6b4a0d8ad38f6f11fecd16",
            "1272f7b78d2144cfb8fa0b9950e04a16",
            "a3ddca31ce6c418d9d70add860f9f7f8",
            "6a195ab7ae054d4b9a9e631b52b0be7c",
            "38d3a450fe194c24a40439ab914a0c1b",
            "9459f69da29e4acfbbf929a4f458fde0",
            "13c866a6fd6240259a4e42dafb0abba2",
            "9adb2af410494d68bcc3ba7defca0ded",
            "3e2a14190f5844058c4f98fecb4865d1",
            "a3ddd2fcfb2f45c891eb2d855ffe99ad",
            "ca14e3d9d083432cb02b07a081e03fa3",
            "a1d90582c7204b84b22144af56a4ddc3",
            "5388c4b7a0244bdca321b2f78ee53155",
            "b1d9ed16b2e645cf898576405eaf8bb3",
            "617a3ed7b6ea4240a624d755912f4e5d",
            "7483e1e9073243adb96a20b96d530b73",
            "1127bd9010a44bdf860d699b96e980e6",
            "c57c6dd8313a4b3a8594746a0ad46754",
            "2a97220df6dd4e94b0eba34458a24c27",
            "adf77c13d01d435d966e6b3ff8e1c7bb",
            "4a3aaf2d1ee941d6847fbdd030af1d08",
            "4c5e72aa4bbd4bbc9f02d2f8aa359dc7",
            "73ce0293e280414f8c7fd6f749feaafb",
            "ca9d4af9020546caa76631492ea712a8"
          ]
        },
        "id": "XfRbFmyhASLK",
        "outputId": "78bbadd5-abab-48b7-d3b6-1e1c5a0d6dc2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e43531da4524455092193cac61d25f0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.56k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bac00ac8850c4f1f8c7ac2d23029ec9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49607e900b7b47edbc06f3a477055fd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a96eec6ff06d41ba9cfadef716e9c277",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "815bb528ca4c43dca9383e80a3338521",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3ddca31ce6c418d9d70add860f9f7f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1d9ed16b2e645cf898576405eaf8bb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dialogue: \n",
            "Jill: so how was your date anyway? :)\r\n",
            "Susan: it was perfect, he was so sweet!! <3\r\n",
            "Jill: tell me everything!!\r\n",
            "Susan: so first he picked me up from home, all dressed up and everything\r\n",
            "Jill: suit on? :D\r\n",
            "Susan: nooo, not like that, but he had a really nice black shirt, elegant shoes, looked like Brad Pitt hahaha\r\n",
            "Jill: hahahahaha\r\n",
            "Susan: <file_gif>\r\n",
            "Jill: so where did he take you?\r\n",
            "Susan: that's the best part! We went to rollerskating disco!!!\r\n",
            "Jill: rollerskating what? are you serious? :/\r\n",
            "Susan: no no, listen - it was so awesome, I am tired of all this dull restaurant dates and stuff, it was actually something original\r\n",
            "Jill: if you say so...\r\n",
            "Susan: you are just jealous Jill :D\r\n",
            "Jill: I am not!!!!!!!\r\n",
            "Susan: yes you are :*\n",
            "---------------\n",
            "flan-t5-base summary:\n",
            "Susan's date was perfect. He picked her up from home and took her to rollerskating disco. She is tired of dull restaurant dates.\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "from transformers import pipeline\n",
        "from random import randrange\n",
        "\n",
        "# load model and tokenizer from huggingface hub with pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"mohammedRiad/flant5-summaryModel\", device=0)\n",
        "\n",
        "# select a random test sample\n",
        "sample = dataset['test'][randrange(len(dataset[\"test\"]))]\n",
        "print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
        "\n",
        "# summarize dialogue\n",
        "res = summarizer(sample[\"dialogue\"])\n",
        "\n",
        "print(f\"flan-t5-base summary:\\n{res[0]['summary_text']}\")"
      ]
    }
  ]
}